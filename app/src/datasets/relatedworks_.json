[[-8.5159749985,-1.1692181826,"title: Local Affine Multidimensional Projection, abstract: Multidimensional projection techniques have experienced many improvements lately, mainly regarding computational times and accuracy. However, existing methods do not yet provide flexible enough mechanisms for visualization-oriented fully interactive applications. This work presents a new multidimensional projection technique designed to be more flexible and versatile than other methods. This novel approach, called Local Affine Multidimensional Projection (LAMP), relies on orthogonal mapping theory to build accurate local transformations that can be dynamically modified according to user knowledge. The accuracy, flexibility, and computational efficiency of LAMP is confirmed by a comprehensive set of comparisons. LAMP\u2019s versatility is exploited in an application which seeks to correlate data that, in principle, has no connection as well as in visual exploration of textual documents., authors: [{'name': 'Paulo Joia', 'affiliation': 'Universidade de S\u00e3o Paulo, Brazil'}, {'name': 'Fernando V. Paulovich', 'affiliation': 'Dalhousie University'}, {'name': 'Danilo Coimbra', 'affiliation': 'Universidade Federal da Bahia'}, {'name': 'Jos\u00e9 Alberto Cuminato', 'affiliation': 'University of S\u00e3o Paulo'}, {'name': 'Luis Gustavo Nonato', 'affiliation': 'University of S\u00e3o Paulo'}], publicationVenue: IEEE Transactions on Visualization and Computer Graphics, publicationDate: December 2011, keywords: ['Multidimensional Projection', 'High Dimensional Data', 'Visual Data Mining'], theoreticalFramework: The research is grounded in orthogonal mapping theory, which ensures robustness and accuracy in the process of multidimensional projection., mainPoints: ['Introduction of a novel multidimensional projection technique called Local Affine Multidimensional Projection (LAMP).', 'LAMP is designed to be more flexible and versatile for interactive applications compared to existing methods.', 'The technique is based on orthogonal mapping theory for building accurate local transformations.', \"LAMP's accuracy, flexibility, and computational efficiency are confirmed through comprehensive comparisons.\", 'The versatility of LAMP is demonstrated through applications in data correlation and visual exploration of textual documents.'], results: LAMP was found to be highly accurate and computationally efficient, outperforming existing methods in terms of stress minimization and computational times. It also demonstrated flexibility in incorporating user knowledge into the projection process., applications: ['Correlating data sets that have no explicit connection, such as correlating images and music to create synchronized slide shows.', 'Visual exploration and organization of textual documents, making it easier to identify and group similar documents.'], additionalInformation: ['LAMP can perform projections using a reduced number of control points, making it suitable for interactive applications.', \"The technique's robustness to the number of control points and its ability to dynamically incorporate user interactions are key contributions to the field.\", 'Future research directions include investigating better mechanisms to assess the impact of user interaction on the quality of the projection and exploring alternative neighborhood definition schemes.'], methodology.dataCollection: The methodology involves selecting a subset of control points from the data and manipulating these points in the visual space to guide the projection process., methodology.dataAnalysis: LAMP relies on a mathematical formulation derived from orthogonal mapping theory to compute affine transformations for projecting data instances into a visual space.",0],[-8.0228891373,-0.7601813078,"title: Exploring Collections of research publications with Human Steerable AI, abstract: Understanding highly-dimensional data sets is a complex task. This paper proposes an inexpensive neural encoder approach to performing backward and forward computations within semantic interaction pipelines for analyzing textual data. It demonstrates the approach with the Zexplorer system, a tool for exploring Large Document Collections of Research papers with Semantic Interaction, built as an extension to Zotero., authors: [{'name': 'Alberto Gonz\u00e1lez Mart\u00ednez', 'affiliation': 'University of Hawaii (LAVA), Honolulu, United States, Hawaii'}, {'name': 'Billy Troy Wooton', 'affiliation': 'University of Hawaii (LAVA), Honolulu, United States, Hawaii'}, {'name': 'Nurit Kirshenbaum', 'affiliation': 'University of Hawaii (LAVA), Honolulu, United States, Hawaii'}, {'name': 'Dylan Kobayashi', 'affiliation': 'University of Hawaii (LAVA), Honolulu, United States, Hawaii'}, {'name': 'Jason Leigh', 'affiliation': 'University of Hawaii (LAVA), Honolulu, United States, Hawaii'}], publicationVenue: PEARC \u201920, July 26\u201330, 2020, Portland, OR, USA, publicationDate: 2020, keywords: ['semantic interaction', 'encoder', 'sensemaking', 'visual analytics', 'text visualization', 'machine learning', 'dimensionality reduction', 'human in the loop'], theoreticalFramework: The research is grounded in the challenges of understanding highly-dimensional data sets, particularly through the lens of Semantic Interaction in Visual Analytics systems, which allows for model steering based on user interactions., mainPoints: ['Traditional pipelines for analyzing highly-dimensional data are limited by their linear, algorithm-driven nature, which can mask known structures in the data.', 'Semantic Interaction provides a way to adjust model parameters based on user interactions, but is traditionally limited to linear models.', 'The paper proposes using a neural encoder to approximate non-linear algorithms like UMAP, allowing for efficient model steering in Semantic Interaction systems.', 'The Zexplorer system demonstrates the practical application of this approach in exploring large collections of research publications.'], results: The approach allows for the efficient merging of new instances into a previously trained model without retraining and provides a reverse link for model parameter adjustment based on user interactions, as demonstrated with the Zexplorer system., applications: ['Enabling researchers to explore large document collections more intuitively by steering the analysis model to align with their mental model.', 'Facilitating the discovery of new insights in multidimensional data sets by allowing non-expert users to interactively adjust model parameters.'], additionalInformation: ['The study highlights the limitations of traditional Semantic Interaction systems in using linear models and proposes a novel solution.', 'Future research directions include exploring more advanced types of model manipulations and expanding the system for multi-user analytics.', 'The research contributes to the field by providing a method to incorporate non-linear algorithms into Semantic Interaction pipelines, enhancing the usability and effectiveness of visual analytics tools.'], methodology.dataCollection: The study utilizes research publications' textual data, converting raw data into abstract numeric representations for analysis., methodology.dataAnalysis: The analysis involves backward and forward computations with a neural encoder to approximate the outputs of non-linear dimensionality reduction algorithms, enabling user-driven model steering.",2],[-7.8285002708,-0.8839429617,"title: Visual Analytics for Topic Model Optimization based on User-Steerable Speculative Execution, abstract: This paper introduces a visual analytics framework for optimizing topic models through user-steerable speculative execution. It presents an explainable, mixed-initiative topic modeling framework that integrates speculative execution into the algorithmic decision-making process, allowing users to preview the effects of their interventions before applying them. The approach aims to improve model quality by incorporating user feedback and domain knowledge directly into the modeling process., authors: [{'name': 'Mennatallah El-Assady', 'affiliation': 'University of Konstanz, Germany; University of Ontario Institute of Technology, Canada'}, {'name': 'Fabian Sperrle', 'affiliation': 'University of Konstanz, Germany'}, {'name': 'Oliver Deussen', 'affiliation': 'University of Konstanz, Germany'}, {'name': 'Daniel Keim', 'affiliation': 'University of Konstanz, Germany'}, {'name': 'Christopher Collins', 'affiliation': 'University of Ontario Institute of Technology, Canada'}], publicationVenue: IEEE Transactions on Visualization and Computer Graphics, publicationDate: January 2019, keywords: ['User-Steerable Topic Modeling', 'Speculative Execution', 'Mixed-Initiative Visual Analytics', 'Explainable Machine Learning'], theoreticalFramework: The research is grounded in the concept of speculative execution as a visual analytics paradigm for creating user-steerable preview mechanisms in topic modeling optimization., mainPoints: ['Introduction of an explainable, mixed-initiative topic modeling framework.', 'Integration of speculative execution into the algorithmic decision-making process.', 'Visualization of the model-space of a novel incremental hierarchical topic modeling algorithm.', \"Active incorporation of user's domain knowledge in every step through explicit model manipulation interactions.\", 'Evaluation of the technique through three independent studies confirming topic model quality improvements.'], results: The results indicate that the proposed visual analytics technique enables effective human-in-the-loop decision-making, leading to perceivable improvements in topic model quality., applications: ['Optimization of topic models in visual text analytics.', 'Incorporation of user feedback and domain knowledge into machine learning models.', 'Educational tool for understanding and teaching the process of topic modeling.'], additionalInformation: ['The study highlights the importance of transparency and user involvement in the modeling process for building trust in machine learning models.', 'Future research directions include exploring other potential model-space visualizations and transferring the concept of speculative execution to other problem domains.', 'The work contributes to the field by demonstrating the effectiveness of speculative execution in visual analytics for topic model optimization.'], methodology.dataCollection: The methodology involves the use of document collections for topic modeling, with user interactions guiding the optimization process., methodology.dataAnalysis: Analysis methods include the use of the Incremental Hierarchical Topic Model (IHTM) algorithm, quality metrics evaluation, and speculative execution strategies for model optimization.",-1],[-8.0052051544,-0.4012742043,"title: FacetAtlas: Multifaceted Visualization for Rich Text Corpora, abstract: Documents in rich text corpora usually contain multiple facets of information. FacetAtlas is a multifaceted visualization technique for visually analyzing rich text corpora, combining search technology with advanced visual analytical tools to convey both global and local patterns simultaneously. It introduces unique aspects such as node cliques, multifaceted edges, an optimized density map, automated opacity pattern enhancement, and interactive context switch between facets. The technique is demonstrated through a case study in the healthcare domain, showing its benefits in supporting complex multifaceted data analysis., authors: [{'name': 'Nan Cao', 'affiliation': 'Department of Computer Science and Engineering, Hong Kong University of Science and Technology'}, {'name': 'Jimeng Sun', 'affiliation': 'IBM T.J. Watson Research Center'}, {'name': 'Yu-Ru Lin', 'affiliation': 'Arts Media and Engineering, Arizona State University'}, {'name': 'David Gotz', 'affiliation': 'IBM T.J. Watson Research Center'}, {'name': 'Shixia Liu', 'affiliation': 'IBM China Research Lab'}, {'name': 'Huamin Qu', 'affiliation': 'Department of Computer Science and Engineering, Hong Kong University of Science and Technology'}], publicationVenue: IEEE Transactions on Visualization and Computer Graphics, publicationDate: November\/December 2010, keywords: ['Multi-facet visualization', 'Text visualization', 'Multi-relational Graph', 'Search UI'], theoreticalFramework: The research is grounded in the need for effective tools to navigate and analyze the multifaceted nature of documents in rich text corpora, leveraging information visualization technologies in conjunction with data mining and text analysis tools., mainPoints: ['Introduction of FacetAtlas, a visualization technique for analyzing multifaceted text corpora.', 'Description of unique aspects of FacetAtlas including node cliques, multifaceted edges, optimized density map, and automated opacity pattern enhancement.', 'Demonstration of FacetAtlas through a healthcare case study, highlighting its effectiveness in complex data analysis.'], results: FacetAtlas enables interactive exploration of multifaceted relationships in text corpora, effectively conveying both global and local patterns, and facilitating complex data analysis tasks., applications: ['Patient education in the healthcare domain, helping users understand complex concepts and relationships between diseases.', 'Potential applications in exploring and analyzing multifaceted relationships in other rich text corpora beyond healthcare.'], additionalInformation: ['The study highlights the lack of effective tools for organizing and presenting search retrieval results in a way that reveals multifaceted relations within or across document clusters.', 'Future work includes applying FacetAtlas to more applications, incorporating the time dimension in the visualization, and conducting more thorough user studies.', 'Key contributions include the introduction of a novel visualization technique that combines search technology with visual analytics to support multifaceted data analysis.'], methodology.dataCollection: Transformation of text documents into a multifaceted entity-relational data model through text mining and entity extraction., methodology.dataAnalysis: Visualization module maps indexed entities and relations to a multifaceted visual display, employing algorithms for layout and pattern enhancement.",2],[-8.0302410126,-0.2459665984,"title: Understanding Text Corpora with Multiple Facets, abstract: Text visualization becomes an increasingly more important research topic as the need to understand massive-scale textual information is proven to be imperative for many people and businesses. However, it is still very challenging to design effective visual metaphors to represent large corpora of text due to the unstructured and high-dimensional nature of text. In this paper, we propose a data model that can be used to represent most of the text corpora. Such a data model contains four basic types of facets: time, category, content (unstructured), and structured facet. To understand the corpus with such a data model, we develop a hybrid visualization by combining the trend graph with tag-clouds. We encode the four types of data facets with four separate visual dimensions. To help people discover evolutionary and correlation patterns, we also develop several visual interaction methods that allow people to interactively analyze text by one or more facets. Finally, we present two case studies to demonstrate the effectiveness of our solution in support of multi-faceted visual analysis of text corpora., authors: [{'name': 'Lei Shi', 'affiliation': 'IBM Research - China'}, {'name': 'Furu Wei', 'affiliation': 'IBM Research - China'}, {'name': 'Shixia Liu', 'affiliation': 'IBM Research - China'}, {'name': 'Li Tan', 'affiliation': 'IBM Research - China'}, {'name': 'Xiaoxiao Lian', 'affiliation': 'IBM Research - China'}, {'name': 'Michelle X. Zhou', 'affiliation': 'IBM Research - Almaden'}], publicationVenue: IEEE Symposium on Visual Analytics Science and Technology, publicationDate: October 24 - 29, Salt Lake City, Utah, USA, 2010, keywords: ['text visualization', 'multi-facet data visualization'], theoreticalFramework: The research is grounded in the challenges of designing effective visual metaphors for representing large, unstructured, and high-dimensional text corpora. It leverages theories from text analytics, visual analytics, and interactive design to propose a novel data model and visualization approach., mainPoints: ['Proposition of a general multi-faceted data model for text corpora, classifying data into time, category, content, and structured facets.', 'Development of a hybrid visualization combining trend graphs with tag-clouds to represent the four facets.', 'Introduction of visual interaction methods for analyzing text corpora through evolutionary and correlation patterns.', 'Presentation of two case studies demonstrating the application and effectiveness of the proposed solution.'], results: The proposed solution effectively supports multi-faceted visual analysis of text corpora, enabling users to discover evolutionary and correlation patterns among different facets. The case studies highlight the solution's utility in real-world applications, such as healthcare data analysis and hotel review analysis., applications: ['Visual analysis of healthcare data to identify patterns and correlations among patient records.', 'Analysis of hotel reviews to assist users in making informed decisions based on multi-faceted review data.'], additionalInformation: ['The work is the first to tightly integrate interactive visualization with a multi-faceted data model of text corpora for effective visual representation, navigation, and analytics.', 'Future research directions could explore the extension of the proposed data model and visualization techniques to other domains and the integration of more advanced text analytics methods.'], methodology.dataCollection: The methodology involves the extraction and synthesis of data facets from raw text corpora, including topic extraction, sentiment analysis, and time-sensitive keyword summarization., methodology.dataAnalysis: Data analysis is conducted through Latent Dirichlet Allocation (LDA) for topic modeling, natural language processing techniques for content facet extraction, and the development of a unified data interface for analytics and visualization integration.",2],[-8.2336940765,-1.2472425699,"title: Approximated and User Steerable tSNE for Progressive Visual Analytics, abstract: This paper introduces a controllable tSNE approximation (A-tSNE) to enable interactive data exploration by trading off speed and accuracy. It presents real-time visualization techniques, including a density-based solution and a Magic Lens to inspect the degree of approximation. This feedback allows users to decide on local refinements and steer the approximation level during analysis, demonstrating the technique's effectiveness for interactive data analysis., authors: [{'name': 'Nicola Pezzotti', 'affiliation': 'Delft University of Technology, The Netherlands'}, {'name': 'Boudewijn P. F. Lelieveldt', 'affiliation': 'Delft University of Technology, The Netherlands; Leiden University Medical Center, The Netherlands'}, {'name': 'Laurens van der Maaten', 'affiliation': 'Delft University of Technology, The Netherlands'}, {'name': 'Thomas H\u20acollt', 'affiliation': 'Delft University of Technology, The Netherlands'}, {'name': 'Elmar Eisemann', 'affiliation': 'Delft University of Technology, The Netherlands'}, {'name': 'Anna Vilanova', 'affiliation': 'Delft University of Technology, The Netherlands'}], publicationVenue: IEEE Transactions on Visualization and Computer Graphics, publicationDate: July 2017, keywords: ['High dimensional data', 'Dimensionality reduction', 'Progressive visual analytics', 'Approximate computation'], theoreticalFramework: The research is grounded in the theoretical framework of Progressive Visual Analytics, focusing on improving interactivity in analytics techniques through visualization and interaction with intermediate results., mainPoints: ['Introduction of A-tSNE, an approximated version of tSNE for faster data exploration.', 'Real-time visualization techniques to inspect approximation levels.', 'User steerable refinement process for interactive data analysis.', \"Demonstration of A-tSNE's effectiveness in real-world scenarios and high-dimensional streams.\"], results: The study shows that A-tSNE can significantly reduce the computation time for generating tSNE embeddings without substantially compromising accuracy, enabling real-time and interactive data exploration., applications: ['Interactive exploration of high-dimensional data in real-time.', 'Real-time analysis of high-dimensional streams for monitoring and decision-making.', 'Enhanced user involvement in the analytics process through steerable refinement.'], additionalInformation: ['The study highlights the importance of balancing speed and accuracy in visual analytics.', \"Future research directions include exploring A-tSNE's application in various domains and further optimization for scalability.\", 'Key contributions include the introduction of a user-steerable approximation level and real-time visualization techniques for tSNE.'], methodology.dataCollection: The methodology does not explicitly detail data collection methods as it focuses on the algorithmic development and application of A-tSNE., methodology.dataAnalysis: The research employs approximated K-Nearest Neighborhood (KNN) queries for dimensionality reduction and utilizes a gradient descent optimization for the iterative process of tSNE.",0],[-7.8183102608,-0.2228138149,"title: Parallel Tag Clouds to Explore and Analyze Faceted Text Corpora, abstract: This paper introduces Parallel Tag Clouds (PTCs), a novel visualization technique for exploring differences among facets of large, metadata-rich text corpora. By combining elements from parallel coordinates and traditional tag clouds, PTCs provide rich overviews of document collections, highlighting regional and linguistic differences, particularly in the context of over 600,000 US Circuit Court decisions., authors: [{'name': 'Christopher Collins', 'affiliation': 'University of Toronto'}, {'name': 'Fernanda B. Vi\u00e9gas', 'affiliation': 'IBM Research'}, {'name': 'Martin Wattenberg', 'affiliation': 'IBM Research'}], publicationVenue: IEEE Symposium on Visual Analytics Science and Technology, publicationDate: October 12 - 13, Atlantic City, New Jersey, USA, 2009, keywords: ['Text visualization', 'corpus visualization', 'information retrieval', 'text mining', 'tag clouds'], theoreticalFramework: The research is grounded in the concept of 'distant reading', a statistical tool-based approach for gaining insights into large text corpora, and the need for visualization methods to aid in the analysis and exploration of automated text processing results., mainPoints: ['Introduction of Parallel Tag Clouds (PTCs) as a method for visualizing differences in large text corpora.', 'Application of PTCs to over 600,000 US Circuit Court decisions to discover regional and linguistic differences.', 'Combination of graphical elements from parallel coordinates and tag clouds for rich document collection overviews.', 'Enhancement of PTCs with interactive features for detailed exploration.', 'Addressing text mining challenges such as selecting the best words to visualize and maintaining interactivity.'], results: Discovery of regional and linguistic differences between courts, with PTCs effectively revealing significant absence or overuse of words across different facets of the data. The visualization technique facilitated rich overviews and acted as an entry point for deeper analysis., applications: ['Exploration and analysis of large, faceted text corpora across various domains beyond legal texts.', 'Augmentation of understanding in fields requiring overview and analysis of large text collections by non-experts.', 'Potential use in linguistic studies, information retrieval, and comparative text analysis.'], additionalInformation: ['The visualization technique is neutral to the scoring method applied, making it adaptable to various metrics beyond the G2 statistic used in this study.', 'Future research directions include exploring automatic column reordering, interactive reordering, and extending the approach to multi-word phrases.', 'The study highlights the importance of interactive visualization tools in uncovering patterns and insights in large-scale text data.'], methodology.dataCollection: Analysis of over 600,000 US Circuit Court decisions, with metadata used to define facets such as court, date, and document parts., methodology.dataAnalysis: Use of text mining to discover distinguishing terms for facets, and a new visualization technique (PTCs) for displaying and interacting with the results. Application of G2 statistic for identifying distinguishing terms.",2],[-8.0864305496,-0.8638164401,"title: FacetLens: Exposing Trends and Relationships to Support Sensemaking within Faceted Datasets, abstract: This work explores the efficacy of interactive visualization systems in supporting exploration and sensemaking within faceted datasets through the development of FacetLens. FacetLens exposes trends and relationships within faceted datasets, implementing linear facets for trend identification and comparison, and pivot operations for navigating dataset relationships., authors: [{'name': 'Bongshin Lee', 'affiliation': 'Microsoft Research'}, {'name': 'Greg Smith', 'affiliation': 'Microsoft Research'}, {'name': 'George G. Robertson', 'affiliation': 'Microsoft Research'}, {'name': 'Mary Czerwinski', 'affiliation': 'Microsoft Research'}, {'name': 'Desney S. Tan', 'affiliation': 'Microsoft Research'}], publicationVenue: CHI 2009, publicationDate: April 4\u20139, 2009, keywords: ['Facets', 'interactive visualization', 'trends', 'relationships', 'sensemaking'], theoreticalFramework: The research is grounded in the understanding of faceted search and interactive visualization systems, focusing on how these can be enhanced to support sensemaking tasks within large datasets., mainPoints: ['FacetLens is an interactive visualization system designed to expose trends and relationships within faceted datasets.', 'Implements linear facets for trend identification and comparison across several trends simultaneously.', 'Offers pivot operations for efficient exploration of dataset relationships.', 'Evaluated through expert use and a formative user study, identifying usability issues and insights gained.'], results: FacetLens demonstrated utility in exposing trends and relationships within datasets, with insights gained from expert use. The formative study identified usability issues and confirmed general success with novice users., applications: ['Supports exploration and sensemaking within large faceted datasets.', 'Can be applied to various datasets without re-authoring, including academic publications and grant data.'], additionalInformation: ['The study identified the need for clearer organization and error recovery mechanisms within the interface.', 'Future work includes improving the user interface, scaling to larger datasets, and exploring a more paper-centric model for dataset exploration.', 'Key contributions include the introduction of linear facets and pivot operations for interactive visualization systems.'], methodology.dataCollection: Expert use case exploration of the CHI publication repository and a database of funding grant data., methodology.dataAnalysis: Formative user study to identify usability issues and gather feedback on the utility of FacetLens.",2],[-7.6852116585,-0.3852767646,"title: Visual Abstraction and Ordering in Faceted Browsing of Text Collections, abstract: This paper reports on a visual support approach toward faceted browsing of a collection of documents based on a set of entities of interest to users. It proposes a multi-dimensional visualization as an alternative to the linear listing of focus items, enabling visual abstraction based on a combination of a conceptual structure and the structural equivalence of documents to deal with a large number of items and support prioritized, cross-facet comparisons., authors: [{'name': 'Vinhtuan Thai', 'affiliation': 'National University of Ireland, Galway'}, {'name': 'Pierre-Yves Rouille', 'affiliation': 'Ecole Nationale Sup\u00e9rieure de Cognitique'}, {'name': 'Siegfried Handschuh', 'affiliation': 'National University of Ireland, Galway'}], publicationVenue: ACM Transactions on Intelligent Systems and Technology, publicationDate: February 2012, keywords: ['Faceted browsing', 'text collections', 'visual exploration'], theoreticalFramework: The research is guided by the need for improved user experience in faceted browsing interfaces, particularly for text collections without clean metadata. It leverages theories related to information visualization, user interface design, and human-computer interaction., mainPoints: ['Introduction of a multi-dimensional visualization for faceted browsing of text collections.', 'Proposal of visual abstraction techniques including semantic zooming and document grouping based on structural equivalence.', 'Introduction of visual, interactive ordering based on facet values to support prioritized comparisons.', 'Conduct of a user study to evaluate the effectiveness of the proposed approach.'], results: The study found that interfaces employing the proposed matrix-based representation supported users better in exploratory tasks and were preferred over traditional linear listing interfaces., applications: ['Enhanced user interfaces for digital libraries and document collections.', 'Improved tools for researchers and professionals needing to explore large text datasets.'], additionalInformation: ['The study highlights the limitations of existing faceted browsing interfaces in handling text collections.', 'Future research directions include exploring the scalability of the proposed approach and its application to other types of digital resources.', 'The paper contributes to the field by demonstrating the benefits of integrating visual abstraction and ordering in faceted browsing interfaces.'], methodology.dataCollection: User study with 18 participants, using a set of 38180 emails from the Enron email dataset., methodology.dataAnalysis: Analysis of user performance and preferences through a within-subjects design, measuring relevant browse speed and collecting subjective ratings.",2],[-7.9906635284,-0.1131023467,"title: ConceptScope: Organizing and Visualizing Knowledge in Documents based on Domain Ontology, abstract: Current text visualization techniques typically provide overviews of document content and structure using intrinsic properties such as term frequencies, co-occurrences, and sentence structures. Such visualizations lack conceptual overviews incorporating domain-relevant knowledge, needed when examining documents such as research articles or technical reports. To address this shortcoming, we present ConceptScope, a technique that utilizes a domain ontology to represent the conceptual relationships in a document in the form of a Bubble Treemap visualization. Multiple coordinated views of document structure and concept hierarchy with text overviews further aid document analysis. ConceptScope facilitates exploration and comparison of single and multiple documents respectively. We demonstrate ConceptScope by visualizing research articles and transcripts of technical presentations in computer science. In a comparative study with DocuBurst, a popular document visualization tool, ConceptScope was found to be more informative in exploring and comparing domain-specific documents, but less so when it came to documents that spanned multiple disciplines., authors: [{'name': 'Xiaoyu Zhang', 'affiliation': 'Department of Computer Science, University of California, Davis, Davis, California'}, {'name': 'Senthil Chandrasegaran', 'affiliation': 'Faculty of Industrial Design Engineering, Delft University of Technology, 2628 CE Delft, The Netherlands'}, {'name': 'Kwan-Liu Ma', 'affiliation': 'Department of Computer Science, University of California, Davis, Davis, California'}], publicationVenue: CHI Conference on Human Factors in Computing Systems (CHI \u201921), publicationDate: May 8\u201313, 2021, keywords: ['Visualization', 'Ontology', 'Knowledge Representation'], theoreticalFramework: The research is grounded in the need for domain-specific knowledge representation in document visualization, leveraging ontologies to provide a structured and conceptual overview of document content., mainPoints: ['Introduction of ConceptScope, a novel text visualization technique.', 'Utilization of domain ontology for conceptual relationship representation.', 'Implementation of Bubble Treemap visualization for concept hierarchy.', 'Facilitation of document exploration and comparison through coordinated views.', \"Demonstration of ConceptScope's utility in computer science document visualization.\", \"Comparative analysis with DocuBurst, highlighting ConceptScope's domain-specific advantages.\"], results: ConceptScope was found to be more informative and effective in exploring and comparing domain-specific documents compared to DocuBurst, especially for documents within a single discipline. However, it was less effective for documents spanning multiple disciplines., applications: ['Enhanced exploration and comparison of research articles and technical reports.', 'Improved understanding of document content through domain-relevant conceptual overviews.', 'Facilitation of knowledge discovery and learning in specific domains.'], additionalInformation: [\"ConceptScope's domain-dependency limits its applicability for interdisciplinary documents.\", 'Future research directions include extending ConceptScope to support multiple domain ontologies and exploring its application in real-time text visualization contexts.', 'The study highlights the importance of incorporating domain-specific knowledge in document visualization tools for more meaningful and informative overviews.'], methodology.dataCollection: The study involved visualizing research articles and technical presentation transcripts in computer science to demonstrate ConceptScope's capabilities., methodology.dataAnalysis: A comparative study with DocuBurst was conducted to evaluate ConceptScope's effectiveness in providing informative overviews for domain-specific documents.",2],[-7.1292939186,-0.7336743474,"title: Large Language Models Enable Few-Shot Clustering, abstract: This paper explores the effectiveness of Large Language Models (LLMs) in enhancing semi-supervised text clustering with minimal expert feedback. It demonstrates that LLMs can significantly improve clustering by being incorporated at different stages: before clustering to improve input features, during clustering to provide constraints, and after clustering for post-correction. The study finds notable improvements in cluster quality when LLMs are used in the first two stages and highlights the potential for LLMs to balance cost and accuracy in clustering tasks., authors: [{'name': 'Vijay Viswanathan', 'affiliation': 'Carnegie Mellon University'}, {'name': 'Kiril Gashteovski', 'affiliation': 'NEC Laboratories Europe'}, {'name': 'Carolin Lawrence', 'affiliation': 'NEC Laboratories Europe'}, {'name': 'Tongshuang Wu', 'affiliation': 'Carnegie Mellon University'}, {'name': 'Graham Neubig', 'affiliation': 'Carnegie Mellon University, Inspired Cognition'}], publicationVenue: arXiv, publicationDate: 2 Jul 2023, keywords: ['Large Language Models', 'Few-Shot Clustering', 'Semi-Supervised Clustering', 'Text Clustering', 'LLM-Guided Clustering'], theoreticalFramework: The study is grounded in the theory of semi-supervised clustering, which posits that incorporating expert knowledge or feedback can guide the clustering process to better align with human intent., mainPoints: ['LLMs can significantly enhance semi-supervised text clustering with minimal expert input.', 'LLMs are effective at different stages of clustering: improving input features, providing clustering constraints, and post-clustering correction.', 'Incorporating LLMs early in the clustering process (before and during) yields the most significant improvements.', 'LLMs enable a trade-off between cost and accuracy, allowing for the production of desired clusters with reduced expert involvement.'], results: The study finds that LLMs consistently improve the quality of clusters across all datasets when used to enrich document representations or provide pairwise constraints. However, LLM post-correction offers limited benefits., applications: ['Enhancing semi-supervised clustering in various domains such as online banking, social media analysis, and knowledge base construction.', 'Reducing the need for extensive expert feedback in clustering tasks, making large-scale data organization more feasible.'], additionalInformation: ['The study highlights the cost-effectiveness of using LLMs for clustering, showing that LLMs can achieve near-human performance at a fraction of the cost.', 'Future research directions include exploring more elaborate methods for document expansion via LLMs and investigating the scalability of LLM-guided clustering for larger datasets.', 'The key contribution of this work is demonstrating the practical utility of LLMs in improving semi-supervised clustering with minimal expert input.'], methodology.dataCollection: The study uses five datasets across three tasks: canonicalizing entities, clustering queries by intent, and grouping tweets by topic., methodology.dataAnalysis: The effectiveness of LLMs in clustering is evaluated by comparing traditional K-Means clustering on document embeddings with LLM-enhanced methods across various metrics.",-1],[-7.2675914764,-0.0247045383,"title: One Embedder, Any Task: Instruction-Finetuned Text Embeddings, abstract: This paper introduces INSTRUCTOR, a novel method for computing text embeddings tailored to different downstream tasks and domains without further training, by embedding text inputs together with instructions explaining the use case. The method outperforms previous models on a variety of embedding evaluation tasks, demonstrating the robustness and versatility of instruction-finetuned embeddings., authors: [{'name': 'Hongjin Su', 'affiliation': 'The University of Hong Kong'}, {'name': 'Weijia Shi', 'affiliation': 'University of Washington'}, {'name': 'Jungo Kasai', 'affiliation': 'University of Washington'}, {'name': 'Yizhong Wang', 'affiliation': 'University of Washington'}, {'name': 'Yushi Hu', 'affiliation': 'University of Washington'}, {'name': 'Mari Ostendorf', 'affiliation': 'University of Washington'}, {'name': 'Wen-tau Yih', 'affiliation': 'Meta AI'}, {'name': 'Noah A. Smith', 'affiliation': 'University of Washington, Allen Institute for AI'}, {'name': 'Luke Zettlemoyer', 'affiliation': 'University of Washington, Meta AI'}, {'name': 'Tao Yu', 'affiliation': 'The University of Hong Kong'}], publicationVenue: Association for Computational Linguistics (ACL) 2023, publicationDate: July 9-14, 2023, keywords: ['Text Embeddings', 'Instruction-Finetuning', 'Downstream Tasks', 'Domain Adaptation', 'Contrastive Loss'], theoreticalFramework: The research is grounded in the concept of instruction-based finetuning and contrastive learning, aiming to create a single embedder capable of generating task- and domain-aware embeddings., mainPoints: ['Introduction of INSTRUCTOR, a method for computing text embeddings with instructions.', 'Annotation of instructions for 330 diverse tasks and training on a multitask mixture with a contrastive loss.', 'Evaluation of INSTRUCTOR on 70 embedding tasks, showing state-of-the-art performance.', \"Analysis of INSTRUCTOR's robustness to instruction changes and its ability to mitigate training challenges on diverse datasets.\"], results: INSTRUCTOR achieves state-of-the-art performance on a wide range of downstream applications, significantly outperforming prior models with an average improvement of 3.4% over 70 diverse datasets., applications: ['Adaptation of text embeddings to various downstream tasks without further training.', 'Improvement of performance across diverse domains such as finance, medicine, and news.'], additionalInformation: ['INSTRUCTOR is robust to changes in instructions, demonstrating the effectiveness of instruction finetuning.', \"The diversity of the MEDI dataset contributes to the model's robustness to paraphrases in instructions.\", 'Future work could explore scaling up the model and applying multitask instruction finetuning to larger models.'], methodology.dataCollection: Collection of 330 text embedding datasets newly annotated with human-written task instructions (MEDI dataset)., methodology.dataAnalysis: Training of INSTRUCTOR with a contrastive loss over all datasets, maximizing similarity between semantically related text pairs while minimizing unrelated pairs.",-1],[-7.1974096298,-0.5846180916,"title: CLUSTERLLM: Large Language Models as a Guide for Text Clustering, abstract: We introduce CLUSTERLLM, a novel text clustering framework that leverages feedback from an instruction-tuned large language model, such as ChatGPT. CLUSTERLLM exhibits advantages by utilizing the emergent capability of LLMs for text clustering, understanding user preferences through textual instruction, and fine-tuning embedders with cost-efficient strategies., authors: [{'name': 'Yuwei Zhang', 'affiliation': 'University of California, San Diego'}, {'name': 'Zihan Wang', 'affiliation': 'University of California, San Diego'}, {'name': 'Jingbo Shang', 'affiliation': 'University of California, San Diego'}], publicationVenue: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, publicationDate: December 6-10, 2023, keywords: ['Text Clustering', 'Large Language Models', 'Embedding Visualization', 'Dimensionality Reduction', 'ChatGPT'], theoreticalFramework: The research is guided by the theoretical framework that large language models (LLMs) can provide high-level language understanding and guidance for clustering tasks, even when direct access to embeddings is not available., mainPoints: ['Introduction of CLUSTERLLM, a framework for text clustering using LLMs like ChatGPT.', \"Demonstration of CLUSTERLLM's advantages over traditional unsupervised methods.\", 'Development of a cost-efficient querying strategy for LLMs to guide clustering.', 'Extensive experiments on 14 datasets showing consistent improvements in clustering quality.'], results: CLUSTERLLM consistently improves clustering quality across various datasets at an average cost of ~$0.61 per dataset, demonstrating effectiveness in both perspective fine-tuning and granularity determination., applications: ['Enhancing text clustering tasks with LLM guidance.', 'Improving the understanding of user preferences in unsupervised clustering scenarios.', 'Cost-efficiently leveraging LLMs for fine-tuning embedders in text clustering.'], additionalInformation: ['The study highlights the potential of LLMs in guiding clustering without direct access to embeddings.', 'Future research directions include exploring model-free training and reducing computational costs.', 'The paper contributes to the field by demonstrating a novel use of LLMs in unsupervised text clustering.'], methodology.dataCollection: The methodology involves constructing hard triplet questions and pairwise questions to query ChatGPT for insights on clustering perspective and granularity., methodology.dataAnalysis: Analysis includes entropy-based triplet sampling for fine-tuning embedders and measuring consistency between LLM predictions and hierarchical clustering to determine cluster granularity.",-1],[-7.4447188377,-0.6999708414,"title: DClusterE: A Framework for Evaluating and Understanding Document Clustering Using Visualization, abstract: This article presents DClusterE, a comprehensive and effective framework for document clustering evaluation and understanding using information visualization. DClusterE integrates cluster validation with user interactions and offers rich visualization tools for users to examine document clustering results from multiple perspectives., authors: [{'name': 'Yi Zhang', 'affiliation': 'Florida International University'}, {'name': 'Tao Li', 'affiliation': 'Florida International University'}], publicationVenue: ACM Transactions on Intelligent Systems and Technology, publicationDate: February 2012, keywords: ['Document analysis', 'Clustering', 'Visualization', 'Performance evaluation'], theoreticalFramework: The research is grounded in the need for effective evaluation and understanding of document clustering results beyond traditional quantitative measures, leveraging information visualization techniques., mainPoints: ['Introduction of DClusterE, a framework for visual evaluation of document clustering.', 'Integration of cluster validation with user interactions for a comprehensive analysis.', 'Proposal of a novel multiplicative update algorithm (MUA) for matrix reordering.', 'Use of a Mallows-distance-based algorithm for relating clustering results to ground truth.'], results: Experiments and user studies demonstrate the effectiveness and efficiency of DClusterE in providing a comprehensive and interactive environment for evaluating and understanding document clustering results., applications: ['Facilitates the evaluation of document clustering performance from multiple perspectives.', 'Enables users to glean insights into document inter\/intra-clustering structures and their relationship with the ground truth.', 'Supports general user interactions such as zoom in\/out, browsing, and interactive access of documents at different levels.'], additionalInformation: ['DClusterE supports a rich set of user-friendly interactive rendering operations based on domain knowledge.', 'The framework includes an integrated visual environment where relationships among clusters or individual documents can be visualized directly and clearly.', 'Future research directions could include the extension of DClusterE to other types of data clustering beyond documents.'], methodology.dataCollection: Use of three common document datasets named CSTR, Log, and DBLP for evaluation., methodology.dataAnalysis: Application of information visualization techniques, including force-directed layout view, matrix view, and cluster view, combined with novel algorithms for matrix reordering and establishing relationships between clustering results and ground truth.",1],[-7.7879686356,-0.3538465202,"title: Termite: Visualization Techniques for Assessing Textual Topic Models, abstract: Topic models aid analysis of text corpora by identifying latent topics based on co-occurring words. Real-world deployments of topic models often require intensive expert verification and model refinement. This paper presents Termite, a visual analysis tool for assessing topic model quality. Termite uses a tabular layout to promote comparison of terms both within and across latent topics. It introduces a novel saliency measure for selecting relevant terms and a seriation algorithm that reveals clustering structure and promotes the legibility of related terms. Through examples, it demonstrates how Termite allows analysts to identify coherent and significant themes., authors: [{'name': 'Jason Chuang', 'affiliation': 'Stanford University Computer Science Department'}, {'name': 'Christopher D. Manning', 'affiliation': 'Stanford University Computer Science Department'}, {'name': 'Jeffrey Heer', 'affiliation': 'Stanford University Computer Science Department'}], publicationVenue: AVI '12, publicationDate: May 21-25, 2012, keywords: ['Topic Models', 'Text Visualization', 'Seriation'], theoreticalFramework: The research is grounded in the need for effective visualization tools to assess the quality of topic models, particularly Latent Dirichlet Allocation (LDA), by identifying coherent and significant themes within text corpora., mainPoints: ['Termite is introduced as a visual analysis tool for assessing the quality of topic models.', 'A novel saliency measure is proposed for ranking and filtering terms to surface more discriminative terms for faster assessment and comparison of topics.', 'A seriation method is introduced for sorting terms to reveal clustering patterns and promote legibility of related terms.', \"The tool's effectiveness in enabling rapid classification of coherent or junk topics and revealing topical overlap is demonstrated through examples.\"], results: The results demonstrate that Termite enables users to meaningfully comprehend topical composition, facilitating the identification of coherent concepts and potential 'junk topics'. The saliency measure and seriation method significantly aid in the rapid classification and disambiguation of topics., applications: ['Termite can be used by researchers and analysts to assess the quality of topic models in text corpora, aiding in the identification of coherent themes.', 'The tool supports the domain-specific task of building and refining topic models, potentially improving the utility and reducing the cost of applying topic models for large-scale text analysis.'], additionalInformation: [\"The study suggests that incorporating user inputs for interactive model refinement (e.g., adjusting model parameters, deleting junk topics, merging related topics) could further improve Termite's utility.\", 'Future work involves expanding Termite to visualize the topical composition of documents and adding interactions to support user inputs.'], methodology.dataCollection: The methodology involved training LDA models on abstracts from 372 IEEE InfoVis conference papers from 1995 to 2010., methodology.dataAnalysis: The analysis utilized the Termite system to visualize term-topic distributions, employing a novel saliency measure and seriation method to assess topic model quality.",2],[-7.6206045151,-0.7301025391,"title: Evaluating exploratory visualization systems: A user study on how clustering-based visualization systems support information seeking from large document collections, abstract: This paper presents a formal user study on Newdle, a clustering-based exploratory visualization system (EVS) for large news collections, to shed light on a general methodology for EVS evaluation. The study is built upon cognitive load theory, focusing on the user and the system to evaluate the cognitive process supported by these systems in various information-seeking tasks., authors: [{'name': 'Yujie Liu', 'affiliation': 'Department of Computer Science, University of North Carolina at Charlotte, USA'}, {'name': 'Scott Barlowe', 'affiliation': 'Department of Computer Science, University of North Carolina at Charlotte, USA'}, {'name': 'Yaqin Feng', 'affiliation': 'Department of Mathematics and Statistics, University of North Carolina at Charlotte, USA'}, {'name': 'Jing Yang', 'affiliation': 'Department of Computer Science, University of North Carolina at Charlotte, USA'}, {'name': 'Min Jiang', 'affiliation': 'Affiliate Faculty, International Studies, Affiliate Researcher, Center for Advanced Research in the Humanities, Complex Systems Institute, USA'}], publicationVenue: Information Visualization, publicationDate: 2013, keywords: ['Clustering', 'Cognition', 'Human\u2013computer interaction', 'Information visualization', 'Information seeking'], theoreticalFramework: The study is guided by cognitive load theory, which categorizes cognitive load into intrinsic, extraneous, and germane, focusing on how these aspects influence the learning and information-seeking process in EVSs., mainPoints: ['The study introduces a formal user study methodology for evaluating exploratory visualization systems, particularly clustering-based systems like Newdle.', 'It emphasizes the importance of understanding the cognitive process in EVS evaluations, guided by cognitive load theory.', 'The paper discusses the challenges and approaches in conducting EVS evaluations in laboratory settings, including task design and user variability control.', 'It presents insights into how clustering-based EVSs support various information-seeking tasks and the role of visual representation of cluster semantics.'], results: Summary of the results indicates that clustering-based EVSs like Newdle can significantly benefit complex information-seeking tasks by reducing extraneous cognitive load and enhancing user engagement and learning., applications: ['The findings can guide the design of clustering-based EVSs to better support complex information-seeking tasks.', 'Insights from the study can be applied to improve user experience in large document collection exploration by emphasizing the importance of visual representation of cluster semantics.'], additionalInformation: ['The study highlights the importance of distinguishing between extraneous and germane cognitive load in EVS evaluations.', 'Future research directions include exploring the design space of clustering-based EVSs and evaluating their performance with different clustering methods and visual representations.', 'The study contributes to the field by providing a systematic approach to evaluating the cognitive process in exploratory visualization systems.'], methodology.dataCollection: The study involved 36 subjects using four test beds (Newdle, clustering-only system, NYT website, and a plain system) to perform four typical information-seeking tasks., methodology.dataAnalysis: Analysis included cognitive load measurements, qualitative comments classification, and quantitative measures such as task completion time and the number of topics found.",1],[-7.9041433334,0.0308758747,"title: Interactive Text Visualization with Text Variation Explorer, abstract: Digitalization is changing how research is carried out in all areas of science, including the humanities. This paper addresses the problem of interactive text visualization in the context of sociolinguistic language study by designing and developing a software tool called Text Variation Explorer (TVE) for sociolinguistic language study. It is based on interactive visualization with a direct manipulation user interface, aimed for exploratory corpus linguistics. The TVE software tool has proven to be useful in supporting the study of language variation and change in its social contexts., authors: [{'name': 'Harri Siirtola', 'affiliation': 'TAUCHI \/ VIRG, School of Information Sciences, University of Tampere, Finland'}, {'name': 'Poika Isokoski', 'affiliation': 'TAUCHI \/ VIRG, School of Information Sciences, University of Tampere, Finland'}, {'name': 'Tanja S\u00e4ily', 'affiliation': 'Department of English, University of Helsinki, Finland'}, {'name': 'Terttu Nevalainen', 'affiliation': 'Department of English, University of Helsinki, Finland'}], publicationVenue: 2016 20th International Conference Information Visualisation, publicationDate: 2016, keywords: ['Information visualization', 'text visualization', 'interaction'], theoreticalFramework: The research is grounded in the challenges of visualizing text data, particularly in the context of sociolinguistics, and draws on existing text visualization techniques and methodologies., mainPoints: ['Digitalization impacts research across all sciences, including humanities.', 'Interactive text visualization can enhance sociolinguistic language studies.', 'Text Variation Explorer (TVE) is developed for exploratory corpus linguistics.', 'TVE is language-independent and supports the study of language variation and change.'], results: TVE has proven useful in supporting language variation and change studies, offering insights into text structure, complexity, and variation through interactive visualization., applications: ['Supporting sociolinguistic studies by providing a dashboard for reading and visualizing text structure, variation, and change.', 'Exploratory corpus linguistics, allowing for quick experimentation with text window size and overlap.', 'Language-independent analysis, making it useful in various linguistic contexts.'], additionalInformation: ['The tool is in the process of being updated based on lessons learned from the first version.', 'Future versions will address issues such as corpus analysis, metadata handling, and improved interaction mechanisms.', 'The research was funded by the Academy of Finland, highlighting its significance and potential impact.'], methodology.dataCollection: The methodology involves the use of digital text data, particularly from sociolinguistic studies., methodology.dataAnalysis: Analysis is conducted through interactive visualization techniques, including direct, indirect, and hybrid visualizations, as well as principal component analysis for text clustering.",-1],[-7.2932662964,-0.5493352413,"title: A New Evolving Tree for Text Document Clustering and Visualization, abstract: This paper introduces an evolving model, the Evolving Tree (ETree), as an alternative to the Self-Organizing Map (SOM) for text document clustering and visualization. ETree forms a hierarchical tree structure where nodes can grow, and each leaf node represents a cluster of documents. The study demonstrates the application of ETree in clustering and visualizing articles from the Engineering Conference (ENCON) organized by Universiti Malaysia Sarawak (UNIMAS)., authors: [{'name': 'Wui Lee Chang', 'affiliation': 'Faculty of Engineering, Universiti Malaysia Sarawak, Sarawak, Malaysia'}, {'name': 'Kai Meng Tay', 'affiliation': 'Faculty of Engineering, Universiti Malaysia Sarawak, Sarawak, Malaysia'}, {'name': 'Chee Peng Lim', 'affiliation': 'Centre for Intelligent Systems Research, Deakin University, Geelong, Australia'}], publicationVenue: Soft Computing in Industrial Applications, Advances in Intelligent Systems and Computing 223, publicationDate: 2014, keywords: ['Evolving Tree', 'Text Document Clustering', 'Visualization', 'Self-Organizing Map', 'Online Learning'], theoreticalFramework: The study is grounded in the theory of unsupervised learning and clustering, particularly using neural network models like SOM and its limitations in online learning and pre-determined map size. ETree is proposed as an evolving system that addresses these limitations., mainPoints: ['Introduction of ETree as an alternative to SOM for text document clustering.', 'ETree supports online learning and does not require a pre-determined map size.', \"Experimental study using articles from the ENCON conference to demonstrate ETree's application.\", \"Analysis of ETree's performance in clustering and visualization of text documents.\"], results: The experimental results show that ETree can effectively cluster and visualize text documents, as demonstrated with the ENCON conference articles. The evolving feature of ETree allows for dynamic clustering without the need for re-training with new documents., applications: ['Text document clustering and visualization for academic conferences.', 'Decision support tool for conference organizers to analyze manuscripts and design conference tracks.', 'Potential applications in image and signal processing.'], additionalInformation: ['ETree addresses the limitations of SOM by supporting online learning and eliminating the need for a pre-determined map size.', 'Future work includes developing an ETree with dynamic child node settings and exploring other applications.'], methodology.dataCollection: Articles from the ENCON conference organized by Universiti Malaysia Sarawak (UNIMAS) were used as the dataset for the experimental study., methodology.dataAnalysis: ETree's hierarchical tree structure was analyzed for its ability to cluster and visualize text documents based on their similarities. The learning algorithm of ETree, including determination of the Best Matching Unit (BMU), updating of leaf nodes, and growing of the tree, was utilized.",1],[-8.5041809082,-1.3995893002,"title: Interactive Design of Multidimensional Data Projection Layout, abstract: Projection methods support effective visualizations of multidimensional data. Linear projections are an important subclass, as they allow for interactive visual exploration of the data space and feature sensitivity analysis. The user interaction is usually based on an iterative modification of the projection matrix elements, for example, by the use of a star coordinate widget. However, such interaction mechanisms become inefficient with increasing number of dimensions. We propose to adapt the projection matrix by allowing the user to directly operate on the projection domain. The desired configuration of the projection layout is obtained by adjusting the positions of (freely chosen) control points. The update of the projection matrix is performed according to the interactive modifications by computing a least-square solution of a linear equation system. Changes can be tracked easily using animation. We apply our method to classified multidimensional data and demonstrate that our approach allows for an intuitive and effective design of projections with desired properties like improved class segregation or reduced clutter., authors: [{'name': 'Vladimir Molchanov', 'affiliation': 'Jacobs University, Bremen, Germany'}, {'name': 'Lars Linsen', 'affiliation': 'Jacobs University, Bremen, Germany'}], publicationVenue: Eurographics Conference on Visualization (EuroVis) (2014) Short Papers, publicationDate: 2014, keywords: ['Projections', 'Multidimensional Data', 'Interactive Design', 'Visualization', 'Linear Projections', 'Least-Square Solution', 'Star Coordinates'], theoreticalFramework: The research is grounded in the theory and application of linear projections for multidimensional data visualization, emphasizing the need for interactive and intuitive methods for modifying projection layouts to achieve desired visualization properties., mainPoints: ['Linear projections are key for visualizing multidimensional data due to their simplicity and low computational costs.', 'Existing interaction mechanisms for modifying projections are inefficient for high-dimensional data.', 'A novel technique is proposed that allows users to directly manipulate the projection domain via control points to achieve desired projection layouts.', 'The technique uses a least-square solution to iteratively update the projection matrix based on user modifications.'], results: The proposed method allows for intuitive and effective design of projection layouts with improved properties such as class segregation and reduced clutter. The technique is efficient for any number of data attributes and supports real-time interactive applications., applications: ['Enhancing visual exploration and feature sensitivity analysis of multidimensional data.', 'Improving class segregation and reducing clutter in data visualization for better data interpretation.'], additionalInformation: ['The technique is efficient for datasets with a large number of attributes, overcoming limitations of existing interaction mechanisms.', 'Future research directions could explore extending the method to non-linear projections and further optimizing the interaction process for user-defined layout design.', 'The research contributes to the field by providing a novel, user-friendly approach to designing multidimensional data projections.'], methodology.dataCollection: The methodology involves applying the proposed technique to classified multidimensional data sets, such as the 'Statlog' and 'Ecoli' datasets., methodology.dataAnalysis: Analysis is performed by computing a least-square solution of an overdetermined system of linear equations to update the projection matrix according to user-defined configurations.",0],[-8.1290025711,-0.8329007626,"title: Semantic Interaction for Visual Analytics: Toward Coupling Cognition and Computation, abstract: The paper discusses the concept of semantic interaction as a methodology for enabling users to steer computational models in visual analytics (VA) systems through direct manipulation of visualizations. It emphasizes the importance of coupling human cognition with computational processes to foster discovery and sensemaking in large, complex datasets., authors: [{'name': 'Alex Endert', 'affiliation': 'Pacific Northwest National Laboratory'}], publicationVenue: IEEE Computer Graphics and Applications, publicationDate: July\/August 2014, keywords: ['Semantic Interaction', 'Visual Analytics', 'Sensemaking', 'Model Steering', 'User Interaction', 'Dimensionality Reduction'], theoreticalFramework: The research is grounded in the theoretical framework of sensemaking in visual analytics, emphasizing the integration of human cognitive processes with computational analytics to enhance the understanding and discovery of complex phenomena within large datasets., mainPoints: ['Introduction of semantic interaction as a methodology for model steering in VA systems.', 'Discussion on the importance of user interaction in visual data exploration and sensemaking.', 'Explanation of how semantic interaction captures tacit knowledge from user interactions to steer underlying analytic models.', \"Evaluation of semantic interaction's impact on sensemaking through case studies and user interactions.\"], results: The study found that semantic interaction effectively enables users to steer analytic models through direct manipulation of visualizations, facilitating a deeper engagement with the data and promoting the discovery of insights., applications: ['Enhancing the usability of complex VA systems for non-expert users.', 'Facilitating the exploration and analysis of large volumes of text data.', 'Supporting sensemaking in domains requiring the analysis of heterogeneous datasets.'], additionalInformation: ['The study highlights the potential of semantic interaction to scale to larger data volumes through the malleability of information retrieval techniques.', 'Future research directions include extending semantic interaction to other visual metaphors and analytic models, and exploring its application in streaming data challenges.', 'The paper contributes to the field by providing a novel approach to integrating human cognition with computational analytics in visual data exploration.'], methodology.dataCollection: Observation and recording of user interactions within VA systems during the process of data exploration and analysis., methodology.dataAnalysis: Analysis of the effects of user interactions on the steering of computational models and the resulting changes in visualizations.",2],[-8.2087478638,-1.1657627821,"title: Semantics of Directly Manipulating Spatializations, abstract: This paper discusses the challenges and solutions in allowing users to directly manipulate data points in visualizations to reflect their domain knowledge or explore data structures. It introduces a new algorithm and interaction techniques that consider both moved and unmoved data points in Visual to Parametric Interaction (V2PI), enhancing the ability to capture user's mental models of the data., authors: [{'name': 'Xinran Hu', 'affiliation': 'Virginia Tech'}, {'name': 'Lauren Bradel', 'affiliation': 'Virginia Tech'}, {'name': 'Dipayan Maiti', 'affiliation': 'Virginia Tech'}, {'name': 'Leanna House', 'affiliation': 'Virginia Tech'}, {'name': 'Chris North', 'affiliation': 'Virginia Tech'}, {'name': 'Scotland Leman', 'affiliation': 'Virginia Tech'}], publicationVenue: IEEE Transactions on Visualization and Computer Graphics, publicationDate: December 2013, keywords: ['Visual to parametric interaction', 'visual analytics', 'statistical models'], theoreticalFramework: The research is grounded in the concept of Visual to Parametric Interaction (V2PI), which translates user interactions with visualizations into algorithmic adjustments, enhancing the exploration and understanding of high-dimensional data., mainPoints: ['Introduction of a new algorithm and interaction technique for V2PI that considers both moved and unmoved data points.', 'Design of a sophisticated weighting scheme that incorporates the importance of unmoved data points.', 'Demonstration of the effectiveness of the proposed method through a system evaluation with a cereal grain dataset.'], results: The proposed method improves the ability of V2PI to capture the user's mental model by explicitly considering both moved and unmoved data points, demonstrated through an improved visualization and weighting of data dimensions., applications: [\"Enhancing visual analytics tools to better reflect user's domain knowledge in data exploration.\", 'Improving the interpretability of high-dimensional data visualizations by incorporating user feedback directly.'], additionalInformation: ['The study highlights the ambiguity in interpreting unmoved data points in user interactions and proposes a solution to make user intentions more explicit.', 'Future research directions include refining the interaction techniques for more complex data structures and exploring the application of the proposed method in different domains.', 'The paper contributes to the field by addressing a gap in how user interactions with visualizations are translated into algorithmic adjustments, particularly in the context of high-dimensional data.'], methodology.dataCollection: Use of a cereal grain dataset for demonstration and evaluation of the proposed V2PI algorithm., methodology.dataAnalysis: Application of weighted Multidimensional Scaling (MDS) algorithm and a new pairwise weighting scheme to capture user's mental model of the data more accurately.",0],[-7.9351015091,-1.4098464251,"title: Steerable, Progressive Multidimensional Scaling, abstract: This paper introduces an extension to the spring model approach of Multidimensional Scaling (MDS) that allows interactive exploration of large-scale datasets. The proposed system, MDSteer, employs hierarchical data structures and progressive layouts to enable users to steer the computation of MDS to areas of interest within datasets containing over one million points. This approach facilitates immediate exploration and focuses computational resources on selected areas for refinement., authors: [{'name': 'Matt Williams', 'affiliation': 'University of British Columbia'}, {'name': 'Tamara Munzner', 'affiliation': 'University of British Columbia'}], publicationVenue: IEEE Symposium on Information Visualization 2004, publicationDate: 2004, keywords: ['dimensionality reduction', 'multidimensional scaling', 'interaction techniques', 'data structures', 'clustering algorithms', 'graphs and networks'], theoreticalFramework: The research is grounded in the theory of dimensionality reduction, specifically focusing on Multidimensional Scaling (MDS) as a technique to represent high-dimensional data in lower-dimensional spaces. The work builds on existing MDS approaches, introducing steerability and progressive layout to enhance interactive exploration of large datasets., mainPoints: ['Introduction of a steerable MDS computation engine and visualization tool, MDSteer, for large-scale datasets.', 'Employment of hierarchical data structures and progressive layouts to enable interactive exploration and focus on areas of interest.', \"Demonstration of the system's capability to handle datasets with dimensionalities up to several hundred and cardinalities of over one million.\", 'Presentation of both real and synthetic benchmark datasets to showcase the effectiveness of the proposed approach.'], results: MDSteer provides an immediate overview of the dataset structure, allowing users to begin exploring datasets of over 1 million nodes quickly. The system enables users to interactively select local regions of interest and refine these areas efficiently, demonstrating the ability to explore and steer computational resources to regions of interest for datasets significantly larger than those handled by previous work., applications: ['Interactive exploration of large-scale high-dimensional datasets.', 'Focused analysis of specific areas within large datasets, enabling efficient data exploration and discovery.'], additionalInformation: [\"The system's performance and layout quality were compared against non-steerable approaches, showing that MDSteer allows for immediate and focused exploration without significantly increasing computation time or memory requirements.\", 'Future work includes implementing more efficient nearest-neighbor finding techniques, exploring changes to the selection criteria for neighborhood and random sample sets, and developing a fully progressive algorithm for binning and layout.', 'The research highlights the importance of steerability in MDS for exploring huge datasets, providing a significant contribution to the field of information visualization and dimensionality reduction.'], methodology.dataCollection: The study uses both real-world datasets and common synthetic benchmark datasets with dimensionalities ranging from 3 to 300 and cardinalities of over one million points., methodology.dataAnalysis: The MDSteer algorithm iteratively alternates between layout stages, where a sub-selection of points are added to the set of active points, and binning stages, which organize currently unplaced points into separate spatial regions. This binning strategy allows users to focus the MDS computation on selected areas.",0],[-8.0104513168,-1.3798110485,"title: Embedding Comparator: Visualizing Differences in Global Structure and Local Neighborhoods via Small Multiples, abstract: Embeddings mapping high-dimensional discrete input to lower-dimensional continuous vector spaces have been widely adopted in machine learning applications as a way to capture domain semantics. The Embedding Comparator is an interactive system that presents a global comparison of embedding spaces alongside fine-grained inspection of local neighborhoods. It systematically surfaces points of comparison by computing the similarity of the k-nearest neighbors of every embedded object between a pair of spaces., authors: [{'name': 'Angie Boggust', 'affiliation': 'MIT CSAIL, Cambridge, Massachusetts, USA'}, {'name': 'Brandon Carter', 'affiliation': 'MIT CSAIL, Cambridge, Massachusetts, USA'}, {'name': 'Arvind Satyanarayan', 'affiliation': 'MIT CSAIL, Cambridge, Massachusetts, USA'}], publicationVenue: 27th International Conference on Intelligent User Interfaces (IUI \u201922), publicationDate: March 22\u201325, 2022, keywords: ['machine learning', 'embedding spaces', 'visualization system', 'interactive', 'small multiples'], theoreticalFramework: The research is grounded in the need for systematic exploration and comparison of embedding models, particularly focusing on the global structure and local neighborhoods within embedding spaces., mainPoints: ['The importance of comparing embeddings for deployment or downstream analysis in various disciplines.', 'Introduction of the Embedding Comparator, an interactive system for analyzing embedding models.', 'The system calculates a similarity score for every embedded object based on its reciprocal local neighborhood.', \"Demonstration of the system's utility through case studies across multiple modalities.\"], results: The Embedding Comparator accelerates comparisons by shifting from laborious manual specification to browsing and manipulating visualizations, as validated in evaluations with 15 participants., applications: ['Rapidly revealing insights such as semantic changes following fine-tuning, language changes over time, and differences between models.', 'Supporting use cases like understanding model performance, selecting embeddings for model initialization, and exploring multimodal embeddings.'], additionalInformation: ['The Embedding Comparator is freely available as open-source software.', 'Future work could explore extending the system for n-way model comparisons and incorporating training data to contextualize differences.'], methodology.dataCollection: Semi-structured interviews with 13 embedding users across disciplines to understand current processes and challenges in comparing embeddings., methodology.dataAnalysis: Development of the Embedding Comparator based on insights from interviews, facilitating global and local comparisons of embedding spaces through interactive visualizations.",0],[-8.256439209,-1.1832926273,"title: InterAxis: Steering Scatterplot Axes via Observation-Level Interaction, abstract: Scatterplots are effective visualization techniques for multidimensional data that use two (or three) axes to visualize data items as a point at its corresponding x and y Cartesian coordinates. Typically, each axis is bound to a single data attribute. Interactive exploration occurs by changing the data attributes bound to each of these axes. In this paper, we present InterAxis, a visual analytics technique to properly interpret, define, and change an axis in a user-driven manner. Users are given the ability to define and modify axes by dragging data items to either side of the x or y axes, from which the system computes a linear combination of data attributes and binds it to the axis., authors: [{'name': 'Hannah Kim', 'affiliation': 'Georgia Institute of Technology'}, {'name': 'Jaegul Choo', 'affiliation': 'Korea University'}, {'name': 'Haesun Park', 'affiliation': 'Georgia Institute of Technology'}, {'name': 'Alex Endert', 'affiliation': 'Georgia Institute of Technology'}], publicationVenue: IEEE Transactions on Visualization and Computer Graphics, publicationDate: 25 Oct. 2015, keywords: ['Scatterplots', 'user interaction', 'model steering'], theoreticalFramework: The research is grounded in the principles of semantic interaction techniques, focusing on the tradeoff between direct manipulation of analytic model parameters and semantic interaction approaches that perform model steering through the inference of user actions., mainPoints: ['Introduction of InterAxis, a system for interactive steering of scatterplot axes.', 'Ability for users to define and modify axes through direct interaction with data points.', 'Use of linear combination of data attributes to compute new axes.', \"Demonstration of the system's utility through usage scenarios with real-world datasets.\"], results: The system enables users to interactively explore and understand multidimensional data through user-driven axis definition and modification, facilitating the discovery of meaningful insights., applications: ['Visual analytics for multidimensional data exploration.', 'Interactive data exploration in domains such as vehicle shopping and crime data analysis.'], additionalInformation: ['The system is web-based, implemented using JavaScript and D3 toolkit.', 'Limitations include challenges with non-linear models and sparse data, with suggestions for future improvements.', 'Potential for future work includes enhancing scalability, supporting fine-tuning capabilities, and guiding users towards buried information.'], methodology.dataCollection: Usage of real-world datasets such as car data and crime data for demonstration., methodology.dataAnalysis: Computation of new axes through linear combination of data attributes based on user interaction.",0],[-8.0251913071,-0.6532933712,"title: Multi-Model Semantic Interaction for Text Analytics, abstract: Semantic interaction offers an intuitive communication mechanism between human users and complex statistical models. By shielding the users from manipulating model parameters, they focus instead on directly manipulating the spatialization, thus remaining in their cognitive zone. However, this technique is not inherently scalable past hundreds of text documents. To remedy this, we present the concept of multi-model semantic interaction, where semantic interactions can be used to steer multiple models at multiple levels of data scale, enabling users to tackle larger data problems. We also present an updated visualization pipeline model for generalized multi-model semantic interaction. To demonstrate multi-model semantic interaction, we introduce StarSPIRE, a visual text analytics prototype that transforms user interactions on documents into both small-scale display layout updates as well as large-scale relevancy-based document selection., authors: [{'name': 'Lauren Bradel', 'affiliation': 'Virginia Tech'}, {'name': 'Chris North', 'affiliation': 'Virginia Tech'}, {'name': 'Leanna House', 'affiliation': 'Virginia Tech'}, {'name': 'Scotland Leman', 'affiliation': 'Virginia Tech'}], publicationVenue: IEEE Symposium on Visual Analytics Science and Technology 2014, publicationDate: November 9-14, Paris, France, keywords: ['Visual analytics', 'Semantic Interaction', 'Sensemaking', 'Text Analytics'], theoreticalFramework: The research is guided by the theoretical framework of semantic interaction within visual analytics, focusing on the cognitive processes of users during sensemaking tasks and how these can be supported by multi-model interactions., mainPoints: ['Introduction of multi-model semantic interaction to support text analytics on large datasets.', 'Presentation of an updated visualization pipeline for generalized multi-model semantic interaction.', 'Demonstration of the StarSPIRE prototype, implementing multi-model semantic interaction for unstructured text data.'], results: The multi-model semantic interaction approach enabled users to effectively engage in sensemaking tasks with large datasets, as demonstrated by the StarSPIRE prototype, which was tested on datasets up to 10,000 text documents., applications: ['Enhancing text analytics tools to support analysis of large-scale unstructured text datasets.', 'Improving the usability of visual analytics systems by allowing users to interactively steer multiple models.'], additionalInformation: ['The technique addresses scalability issues in semantic interaction by enabling steering of multiple models.', 'Future research directions include exploring additional models for retrieval and layout, and applying the technique to larger datasets and streaming data.', 'Key contributions include the concept of multi-model semantic interaction and the demonstration of its practical application through the StarSPIRE prototype.'], methodology.dataCollection: Use of unstructured text documents and user interactions as primary data sources., methodology.dataAnalysis: Analysis of user interactions to steer both display layout and relevancy-based document selection models.",2],[-7.8159570694,-0.4737391174,"title: TopicLens: Efficient Multi-Level Visual Topic Exploration of Large-Scale Document Collections, abstract: Topic modeling, which reveals underlying topics of a document corpus, has been actively adopted in visual analytics for large-scale document collections. However, due to its significant processing time and non-interactive nature, topic modeling has so far not been tightly integrated into a visual analytics workflow. TopicLens addresses this gap by proposing a novel interaction technique that allows a user to dynamically explore data through a lens interface where topic modeling and the corresponding 2D embedding are efficiently computed on the fly., authors: [{'name': 'Minjeong Kim', 'affiliation': 'Korea University'}, {'name': 'Kyeongpil Kang', 'affiliation': 'Korea University'}, {'name': 'Deokgun Park', 'affiliation': 'University of Maryland, College Park, MD, USA'}, {'name': 'Jaegul Choo', 'affiliation': 'Korea University'}, {'name': 'Niklas Elmqvist', 'affiliation': 'University of Maryland, College Park, MD, USA'}], publicationVenue: IEEE Transactions on Visualization and Computer Graphics, publicationDate: January 2017, keywords: ['topic modeling', 'nonnegative matrix factorization', 't-distributed stochastic neighbor embedding', 'magic lens', 'text analytics'], theoreticalFramework: The research is grounded in the need for interactive visual analytics in the exploration of large-scale document collections, leveraging topic modeling techniques such as nonnegative matrix factorization and t-distributed stochastic neighbor embedding., mainPoints: ['Introduction of TopicLens, a novel interaction technique for real-time topic modeling within a visual analytics system.', 'Proposal of dynamic hierarchical rank-2 nonnegative matrix factorization (DH-NMF) for efficient topic modeling.', 'Development of guided approximate t-SNE for maintaining view consistency in 2D embedding.', 'Demonstration of TopicLens through a web-based visual analytics system.'], results: TopicLens enables real-time, interactive exploration of document collections, revealing finer-grained topical structures efficiently while maintaining view consistency., applications: ['Real-time visual analytics of large-scale document collections.', 'Interactive exploration of topics within specific areas of interest in a document corpus.'], additionalInformation: ['The study highlights the challenge of integrating computationally intensive topic modeling techniques into interactive visual analytics workflows.', 'Future research directions include exploring other computational and visualization methods within the dynamic lens interface.', 'The study contributes to the field by providing a novel approach to real-time topic modeling and visualization, enhancing the interactivity and efficiency of visual analytics systems.'], methodology.dataCollection: Use of large-scale document collections, including news articles and academic papers., methodology.dataAnalysis: Application of DH-NMF for topic modeling and guided approximate t-SNE for 2D embedding of documents.",2],[-7.6608700752,-0.678155899,"title: TopicRefiner: Coherence-guided Steerable LDA for Visual Topic Enhancement, abstract: This paper presents a new Human-steerable Topic Modeling (HSTM) technique that extends LDA for extracting topics with better applicability and incorporates users' refinements into the Gibbs sampling to control LDA. It addresses the complexity of LDA and the challenge of selecting relevant objects in a vast corpus by designing a visual editing framework based on the coherence metric. The technique's usability and effectiveness are demonstrated through cases on real-world datasets, a user study, and quantitative experiments., authors: [{'name': 'Huan Yang', 'affiliation': 'College of Intelligence and Computing, Tianjin University'}, {'name': 'Jie Li', 'affiliation': 'College of Intelligence and Computing, Tianjin University'}, {'name': 'Siming Chen', 'affiliation': 'School of Data Science, Fudan University'}], publicationVenue: IEEE Transactions on Visualization and Computer Graphics, publicationDate: August 2015, keywords: ['Topic Modeling', 'human-in-the-loop', 'mixed initiative', 'Latent Dirichlet Allocation', 'LDA', 'visual analytics'], theoreticalFramework: The research is grounded in the principles of Latent Dirichlet Allocation (LDA) and extends it by incorporating human-steerable elements for topic refinement, guided by the coherence metric which is consistent with human perception in assessing topic quality., mainPoints: ['Introduction of a weighting method to incorporate user refinements into Gibbs sampling for controlling LDA.', \"Design of a visual editing framework based on the coherence metric to guide users' interactive refinements.\", \"Demonstration of the technique's usability and effectiveness through real-world datasets and a user study.\", 'Proposal of strategies to handle weight conflicts in multiple refinements.'], results: The proposed technique improves the semantic consistency of topics, as demonstrated through cases, user study performance, and quantitative experiments. The overall positive feedback from participants proves the usability and effectiveness of the approach., applications: ['Enhancing topic model outputs for better understanding and exploration of large document sets.', 'Interactive topic editing in fields requiring high-quality topic extraction, such as digital humanities and social media analysis.'], additionalInformation: ['The technique supports rich refinements and improves editing efficiency and security.', 'Future work includes improving the system by introducing more metrics for topic editing and building new interactions around these metrics.'], methodology.dataCollection: Cases on two open real-world datasets and a user study involving participants' performance in topic editing., methodology.dataAnalysis: Quantitative experiments to analyze the performance of the steerable LDA model and the coherence-based topic editing tool.",1],[-7.9351587296,-0.2268621475,"title: ConceptVector: Text Visual Analytics via Interactive Lexicon Building using Word Embedding, abstract: Central to many text analysis methods is the notion of a concept: a set of semantically related keywords characterizing a specific object, phenomenon, or theme. Advances in word embedding allow building a concept from a small set of seed terms. However, naive application of such techniques may result in false positive errors because of the polysemy of natural language. To mitigate this problem, we present a visual analytics system called ConceptVector that guides a user in building such concepts and then using them to analyze documents. Document-analysis case studies with real-world datasets demonstrate the fine-grained analysis provided by ConceptVector. To support the elaborate modeling of concepts, we introduce a bipolar concept model and support for specifying irrelevant words. We validate the interactive lexicon building interface by a user study and expert reviews. Quantitative evaluation shows that the bipolar lexicon generated with our methods is comparable to human-generated ones., authors: [{'name': 'Deokgun Park', 'affiliation': 'University of Maryland in College Park, MD, USA'}, {'name': 'Seungyeon Kim', 'affiliation': 'Google Inc. in Mountain View, CA, USA'}, {'name': 'Jurim Lee', 'affiliation': 'Korea University in Seoul, Republic of Korea'}, {'name': 'Jaegul Choo', 'affiliation': 'Korea University in Seoul, Republic of Korea'}, {'name': 'Nicholas Diakopoulos', 'affiliation': 'Northwestern University in Evanston, IL, USA'}, {'name': 'Niklas Elmqvist', 'affiliation': 'University of Maryland in College Park, MD, USA'}], publicationVenue: IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, publicationDate: January 2018, keywords: ['Text analytics', 'Visual analytics', 'Word embedding', 'Text summarization', 'Text classification', 'Concepts'], theoreticalFramework: The research is grounded in the theory that semantically related keywords can effectively characterize concepts for text analysis. It leverages advances in word embedding to build and refine these concepts interactively., mainPoints: ['Introduction of ConceptVector, a visual analytics system for interactive lexicon building using word embedding.', 'Presentation of a bipolar concept model and the ability to specify irrelevant words for more accurate concept modeling.', 'Validation of the system through a user study, expert reviews, and quantitative evaluation.', \"Demonstration of the system's application in real-world datasets for fine-grained text analysis.\"], results: The system was shown to effectively guide users in building accurate concepts for text analysis. The bipolar lexicon generated was comparable to human-generated lexicons, and the system's utility was demonstrated through case studies., applications: ['Fine-grained text analysis in domains such as finance, journalism, and politics.', 'Customized document analysis for understanding specific themes or phenomena.', 'Support for academic and industry researchers in exploring large text corpora.'], additionalInformation: ['The system addresses the challenge of polysemy in natural language by allowing users to refine concepts interactively.', 'Future research directions include exploring the integration of multiple heterogeneous training data and automatic disambiguation of word meanings.', 'The study highlights the importance of human-machine collaboration in text analytics.'], methodology.dataCollection: Use of real-world datasets and pre-trained word embeddings from Wikipedia articles., methodology.dataAnalysis: Interactive lexicon building guided by word embedding, k-means clustering for word recommendations, and t-SNE for visualizing word relationships. Relevance scoring model based on kernel density estimation.",2],[-7.5232715607,-0.3685208857,"title: TextLuas: Tracking and Visualizing Document and Term Clusters in Dynamic Text Data, abstract: For large volumes of text data collected over time, a key knowledge discovery task is identifying and tracking clusters. These clusters may correspond to emerging themes, popular topics, or breaking news stories in a corpus. This paper proposes a model for tracking dynamic clusters characterized by the evolutionary events of each cluster and introduces the TextLuas system for tracking these dynamic clusters and visualizing their evolution using a metro map metaphor., authors: [{'name': 'Derek Greene', 'affiliation': 'Insight Centre for Data Analytics, University College Dublin, Ireland'}, {'name': 'Daniel Archambault', 'affiliation': 'Department of Computer Science, Swansea University, UK'}, {'name': 'V\u00e1clav Bel\u00e1k', 'affiliation': 'Insight Centre for Data Analytics, NUI Galway, Ireland'}, {'name': 'P\u00e1draig Cunningham', 'affiliation': 'Insight Centre for Data Analytics, University College Dublin, Ireland'}], publicationVenue: arXiv, publicationDate: 2014-11-03, keywords: ['Dynamic text data', 'Cluster tracking', 'Visualization', 'Metro map metaphor', 'Tag cloud'], theoreticalFramework: The research is grounded in the problem of clustering dynamic data and the need for interactive exploration of the output of these analysis techniques, particularly in cases where researchers wish to simultaneously explore both the change in cluster structure over time and the change in the textual content associated with clusters., mainPoints: ['Introduction of a model for tracking dynamic clusters in text data.', 'Development of the TextLuas system for visualizing the evolution of these clusters.', 'Adaptation of the tag cloud representation to dynamic clustering scenarios.', \"Demonstration of the system's application on two different text corpora.\"], results: The TextLuas system elucidates the evolution of key themes in the analyzed text corpora and provides insights into bibliographic network research through the application of the system., applications: ['Interactive exploration of dynamic text data sets for knowledge discovery.', 'Analysis of evolving themes and topics in large volumes of text data over time.', 'Application to bibliographic network research for exploring the evolution of scientific communities.'], additionalInformation: ['The system illustrates the relationship between dynamic clusters using a metro map-style layout.', 'The content contained in these clusters is presented in the form of aggregated tag clouds.', 'Future work may explore dynamic cluster aggregation or filtering for highly volatile data.'], methodology.dataCollection: Analysis of two text corpora, including economic news sources and a Web 2.0 social bookmarking portal., methodology.dataAnalysis: Employment of a heuristic threshold-based matching method for tracking clusters across time steps, and a dynamic spectral co-clustering algorithm for clustering individual time step graphs.",-1],[-7.460226059,-0.7526625991,"title: iVisClustering: An Interactive Visual Document Clustering via Topic Modeling, abstract: Clustering plays an important role in many large-scale data analyses providing users with an overall understanding of their data. Nonetheless, clustering is not an easy task due to noisy features and outliers existing in the data, and thus the clustering results obtained from automatic algorithms often do not make clear sense. To remedy this problem, automatic clustering should be complemented with interactive visualization strategies. This paper proposes an interactive visual analytics system for document clustering, called iVisClustering, based on a widely-used topic modeling method, latent Dirichlet allocation (LDA). iVisClustering provides a summary of each cluster in terms of its most representative keywords and visualizes soft clustering results in parallel coordinates. The main view of the system provides a 2D plot that visualizes cluster similarities and the relation among data items with a graph-based representation., authors: [{'name': 'Hanseung Lee', 'affiliation': 'Georgia Institute of Technology, USA'}, {'name': 'Jaeyeon Kihm', 'affiliation': 'Cornell University, USA'}, {'name': 'Jaegul Choo', 'affiliation': 'Georgia Institute of Technology, USA'}, {'name': 'John Stasko', 'affiliation': 'Georgia Institute of Technology, USA'}, {'name': 'Haesun Park', 'affiliation': 'Georgia Institute of Technology, USA'}], publicationVenue: Eurographics Conference on Visualization (EuroVis) 2012, publicationDate: 2012, keywords: ['Clustering', 'Visual Analytics', 'Document Clustering', 'Topic Modeling', 'Latent Dirichlet Allocation', 'Interactive Visualization'], theoreticalFramework: The research is grounded in the challenges of clustering large-scale data and the limitations of automatic clustering algorithms. It leverages the theoretical underpinnings of Latent Dirichlet Allocation (LDA) for topic modeling and interactive visualization techniques to enhance the clustering process., mainPoints: ['Introduction of iVisClustering, an interactive visual analytics system for document clustering.', 'Utilization of Latent Dirichlet Allocation (LDA) for topic modeling.', 'Provision of multiple interactive visualization modules for refining clustering results.', \"Demonstration of the system's capabilities through usage scenarios.\"], results: The system enables users to refine clustering results interactively, leading to clearer and more meaningful clusters. It demonstrates the effectiveness of combining automatic clustering with interactive visualization., applications: ['Enhancing the understanding of large-scale document datasets.', 'Improving the clustering process by allowing users to interactively refine results.', 'Applicable to various fields such as data mining, machine learning, and information retrieval.'], additionalInformation: [\"The system's design allows for flexibility in clustering tasks through multiple views.\", \"Future research directions include conducting user studies to evaluate the system's usability and efficiency.\", 'Key contributions include the integration of LDA with interactive visualization for document clustering.'], methodology.dataCollection: The system encodes document sets as matrices using a bag-of-words model, after stemming and stop-word removal, to create a term-document matrix., methodology.dataAnalysis: Uses Latent Dirichlet Allocation (LDA) for initial clustering, followed by interactive visual analytics for refining and understanding the clustering results.",1],[-7.1975541115,-1.2401800156,"title: Assisting Users with Clustering Tasks by Combining Metric Learning and Classification, abstract: Interactive clustering refers to situations in which a human labeler assists a learning algorithm in automatically clustering items. This paper presents assisted clustering, where a user creates explicit groups of items from a large set and seeks suggestions on what items to add to each group. The research explores combining metric learning and classification to assist users in clustering tasks, showing that a hybrid mechanism often exceeds the performance of using either method alone., authors: [{'name': 'Sumit Basu', 'affiliation': 'Microsoft Research, Redmond, WA'}, {'name': 'Danyel Fisher', 'affiliation': 'Microsoft Research, Redmond, WA'}, {'name': 'Steven M. Drucker', 'affiliation': 'Microsoft Research, Redmond, WA'}, {'name': 'Hao Lu', 'affiliation': 'University of Washington, Seattle, WA'}], publicationVenue: Association for the Advancement of Artificial Intelligence, publicationDate: 2010, keywords: ['Interactive clustering', 'Assisted clustering', 'Metric learning', 'Classification', 'Hybrid mechanism'], theoreticalFramework: The research is grounded in the theoretical framework of interactive clustering, metric learning, and classification. It explores how these methods can be combined to assist users in clustering tasks more effectively., mainPoints: ['Introduction of assisted clustering, a variant of interactive clustering where users seek suggestions for adding items to groups.', 'Exploration of metric learning and classification as methods to assist in clustering tasks.', 'Development of a hybrid mechanism that combines metric learning and classification, showing improved performance over using either method alone.', 'Presentation of results from trials based on human clusterings, demonstrating the effectiveness of the hybrid approach.'], results: The hybrid mechanism matches and often substantially exceeds the performance of systems that exclusively use either metric learning or classification. The method performs well in both 'cold start' and 'warm start' conditions, with significant improvements in the latter., applications: ['Enhancing interactive clustering systems by providing more effective suggestions for users organizing items into groups.', 'Applicable to various types of data that can be represented visually and for which similarity metrics can be defined.'], additionalInformation: [\"The study's formulation is based on users' observed behavior, highlighting the relevance of both classifiers and metric learners in assisted clustering.\", \"The hybrid method's adaptability suggests potential applicability in other scenarios where both types of learners are relevant.\", 'Future work could explore incorporating more sophisticated individual learners to further improve the overall system performance.'], methodology.dataCollection: Observational study to understand human sorting behavior and development of an interactive system for assisted clustering to collect ground truth data., methodology.dataAnalysis: Experimentation with both metric learning and classification approaches, followed by the development and evaluation of a hybrid mechanism combining both approaches.",-1],[-7.1751570702,-0.9965592027,"title: Helping Users Sort Faster with Adaptive Machine Learning Recommendations, abstract: Sorting and clustering large numbers of documents can be an overwhelming task: manual solutions tend to be slow, while machine learning systems often present results that don\u2019t align well with users\u2019 intents. We created and evaluated a system for helping users sort large numbers of documents into clusters. iCluster has the capability to recommend new items for existing clusters and appropriate clusters for items. The recommendations are based on a learning model that adapts over time \u2013 as the user adds more items to a cluster, the system\u2019s model improves and the recommendations become more relevant. Thirty-two subjects used iCluster to sort hundreds of data items both with and without recommendations; we found that recommendations allow users to sort items more rapidly. A pool of 161 raters then assessed the quality of the resulting clusters, finding that clusters generated with recommendations were of statistically indistinguishable quality. Both the manual and assisted methods were substantially better than a fully automatic method., authors: [{'name': 'Steven M. Drucker', 'affiliation': 'Microsoft Research, 1 Microsoft Way, Redmond, WA. 98052'}, {'name': 'Danyel Fisher', 'affiliation': 'Microsoft Research, 1 Microsoft Way, Redmond, WA. 98052'}, {'name': 'Sumit Basu', 'affiliation': 'Microsoft Research, 1 Microsoft Way, Redmond, WA. 98052'}], publicationVenue: INTERACT 2011, Part III, LNCS 6948, publicationDate: 2011, keywords: ['Mixed initiative interactions', 'adaptive user interfaces', 'information interfaces', 'interactive clustering', 'machine learning'], theoreticalFramework: The research is grounded in the intersection of human-computer interaction and machine learning, particularly focusing on how adaptive machine learning recommendations can enhance user efficiency in sorting and clustering tasks., mainPoints: ['Manual sorting of large document sets is slow and cumbersome, while fully automated systems often do not align with user intent.', 'The iCluster system provides adaptive machine learning recommendations to assist users in sorting documents into clusters more efficiently.', \"The system's recommendations become more relevant as it learns from the user's clustering actions over time.\", 'Empirical evaluation shows that iCluster enables faster sorting without compromising the quality of the resulting clusters compared to manual sorting.', 'Both manual and assisted methods outperform fully automated clustering in terms of cluster quality.'], results: iCluster significantly increased the speed of document sorting by users. Clusters created with iCluster assistance were of comparable quality to those created manually, and both were superior to clusters generated by a fully automated method., applications: ['Enhancing efficiency in organizing large sets of documents or data items across various domains, such as academic research, user feedback analysis, and information management.', 'Improving the usability of machine learning systems for tasks requiring personal or subjective categorization.'], additionalInformation: ['The study confirms the potential of combining human insights with machine learning to improve task efficiency without sacrificing outcome quality.', 'Future research directions include exploring the scalability of iCluster for larger datasets and its applicability to other types of data beyond text documents.', 'The study highlights the importance of adaptive, user-centered design in developing machine learning applications.'], methodology.dataCollection: Observational study of user behavior in manual document clustering, followed by a within-subjects study comparing sorting with and without iCluster assistance., methodology.dataAnalysis: Analysis of sorting speed and cluster quality, with the latter assessed through a separate evaluation by a pool of raters.",-1],[-8.1524057388,-1.1572101116,"title: Observation-Level Interaction with Statistical Models for Visual Analytics, abstract: In visual analytics, sensemaking is facilitated through interactive visual exploration of data. This paper explores how models for visual analytic tools can be designed to allow users to express their reasoning on observations (the data), instead of directly on the model or tunable parameters. It introduces observation-level interactions within the context of three statistical methods: Probabilistic Principal Component Analysis (PPCA), Multidimensional Scaling (MDS), and Generative Topographic Mapping (GTM), discussing their importance in the sensemaking process., authors: [{'name': 'Alex Endert', 'affiliation': 'Department of Computer Science, Virginia Tech'}, {'name': 'Chao Han', 'affiliation': 'Department of Statistics, Virginia Tech'}, {'name': 'Dipayan Maiti', 'affiliation': 'Department of Statistics, Virginia Tech'}, {'name': 'Leanna House', 'affiliation': 'Department of Statistics, Virginia Tech'}, {'name': 'Scotland Leman', 'affiliation': 'Department of Statistics, Virginia Tech'}, {'name': 'Chris North', 'affiliation': 'Department of Computer Science, Virginia Tech'}], publicationVenue: IEEE Symposium on Visual Analytics Science and Technology, publicationDate: October 23 - 28, Providence, RI, USA, 2011, keywords: ['observation-level interaction', 'visual analytics', 'statistical models'], theoreticalFramework: The paper postulates that sensemaking in visual analytics is not focused on parameter adjustments but on perceived connections and patterns within the data. It introduces a framework for integrating user interaction at the observation level with statistical models to facilitate this process., mainPoints: ['Sensemaking in visual analytics is enhanced by focusing on observation-level interactions rather than parameter adjustments.', 'Exploratory and expressive interactions are crucial for integrating user intuition into the sensemaking process.', 'Probabilistic Principal Component Analysis (PPCA), Multidimensional Scaling (MDS), and Generative Topographic Mapping (GTM) can be modified to support observation-level interactions.', 'The paper presents use cases for each statistical method, demonstrating how observation-level interaction can be incorporated into visual analytic tools.'], results: The paper demonstrates that incorporating observation-level interactions into PPCA, MDS, and GTM allows users to more effectively engage in the sensemaking process by leveraging their domain knowledge and intuition directly within the visual analytic tools., applications: ['Enhanced visual analytics tools that support direct user interaction with data points for sensemaking.', 'Improved understanding and insight generation from complex datasets in various domains through interactive visual exploration.'], additionalInformation: ['The study highlights the importance of designing visual analytic tools that support observation-level interaction to facilitate sensemaking.', 'Future research directions include integrating these modified statistical models into fully functional visual analytics tools and evaluating their effectiveness through user studies.', 'The paper contributes to the field by proposing a novel approach to interaction in visual analytics, focusing on data points rather than model parameters.'], methodology.dataCollection: Use cases for GTM, MDS, and PPCA, illustrating observation-level interaction in various contexts., methodology.dataAnalysis: Modification of statistical models to incorporate user interactions directly with the data points in a visualization, and subsequent analysis of the impact on the models' outputs.",0],[-7.1450657845,-1.2196278572,"title: ReGroup: Interactive Machine Learning for On-Demand Group Creation in Social Networks, abstract: ReGroup is an interactive machine learning system designed to assist users in creating custom, on-demand groups within online social networks. By learning from the user's actions of adding members to a group, ReGroup iteratively develops a probabilistic model of group membership, which is then used to suggest additional members and group characteristics for filtering. The evaluation demonstrates ReGroup's effectiveness in facilitating the creation of large and varied groups, highlighting its potential to enhance in-context sharing and promote better online privacy practices., authors: [{'name': 'Saleema Amershi', 'affiliation': 'Computer Science & Engineering, DUB Group, University of Washington'}, {'name': 'James Fogarty', 'affiliation': 'Computer Science & Engineering, DUB Group, University of Washington'}, {'name': 'Daniel S. Weld', 'affiliation': 'Computer Science & Engineering, DUB Group, University of Washington'}], publicationVenue: CHI 2012, publicationDate: May 5\u201310, 2012, keywords: ['Interactive machine learning', 'social network access control', 'example and feature-based interaction', 'User Interfaces'], theoreticalFramework: The research is grounded in the conflict between the desire to share personal lives online and concerns about privacy. It explores the use of interactive machine learning as a tool for enhancing user control over group creation in social networks, thereby addressing privacy concerns., mainPoints: ['ReGroup introduces a novel approach to creating custom groups in social networks through interactive machine learning.', 'The system learns from user actions to suggest potential group members and characteristics, improving the group creation process.', \"Evaluation shows ReGroup's effectiveness in creating large and varied groups compared to traditional methods.\", 'The research identifies challenges in designing user interactions with machine learning systems in the context of social networks.'], results: ReGroup was found to be effective in helping users create large and varied groups, outperforming traditional methods for these types of groups. However, for small groups whose members can be easily recalled, traditional methods were preferred., applications: ['Enhancing privacy and sharing controls in social networks.', 'Facilitating the creation of context-specific groups for targeted content sharing.', 'Improving user experience in managing social network connections and interactions.'], additionalInformation: ['The study highlights the importance of integrating both traditional and machine learning-based methods for group creation to cater to different user needs.', \"Future research directions include exploring additional features to improve ReGroup's model and investigating its application for automatic group maintenance.\", 'The research contributes to the field by demonstrating the potential of interactive machine learning in enhancing user control and privacy in social networks.'], methodology.dataCollection: User interactions with the ReGroup system during the group creation process, including the selection and addition of group members., methodology.dataAnalysis: Analysis of the effectiveness of ReGroup in facilitating group creation, based on quantitative and qualitative data from user evaluations.",-1],[-7.8097238541,-1.5333636999,"title: Dis-Function: Learning Distance Functions Interactively, abstract: The paper presents a system that allows experts to interact directly with a visual representation of their data to define an appropriate distance function, thus avoiding direct manipulation of obtuse model parameters. Through iterative interaction and optimization, users can achieve a scatterplot view and its corresponding distance function that reflects their knowledge of the data. The system's scalability in data size and dimension is evaluated, showing computational efficiency and interactive or near-interactive user experience., authors: [{'name': 'Eli T. Brown', 'affiliation': 'Department of Computer Science, Tufts University'}, {'name': 'Jingjing Liu', 'affiliation': 'Department of Computer Science, Tufts University'}, {'name': 'Carla E. Brodley', 'affiliation': 'Department of Computer Science, Tufts University'}, {'name': 'Remco Chang', 'affiliation': 'Department of Computer Science, Tufts University'}], publicationVenue: Not specified, publicationDate: Not specified, keywords: ['Distance function', 'Interactive visualization', 'Machine learning', 'Data exploration', 'Dimensionality reduction'], theoreticalFramework: The research is grounded in the intersection of machine learning and interactive visualization, focusing on the challenge of defining distance metrics for data analysis and the potential of direct user interaction to guide the learning of these metrics., mainPoints: ['Introduction of a system that allows experts to define distance functions through direct interaction with data visualizations.', 'Adoption of an iterative approach for learning and refining distance functions based on user input.', \"Empirical illustration of the system's ability to learn meaningful distance functions with few iterations of user interaction.\", \"Evaluation of the system's scalability and computational efficiency.\"], results: The system demonstrated the ability to efficiently learn distance functions that reflect user knowledge with interactive or near-interactive performance. The learned distance functions improved classification accuracy in a k-NN classifier compared to unweighted Euclidean distance., applications: ['Enhancing data exploration and analysis by allowing domain experts to define meaningful distance metrics without deep technical knowledge.', 'Facilitating feature selection and dimensionality reduction based on the importance weights assigned through the learned distance functions.'], additionalInformation: [\"The system's user interaction model primarily supports moving data points closer together, with limitations on effectively specifying that points should be further apart.\", 'Future research directions include exploring different types of visualizations and interaction paradigms to capture a wider range of user intentions and expertise.', 'The study highlights the potential of combining machine learning and interactive visualization to make complex data analysis tasks more accessible to domain experts.'], methodology.dataCollection: Use of the modified Wine dataset from the UCI Machine Learning repository for empirical evaluation., methodology.dataAnalysis: Iterative optimization process to learn new distance functions based on user interactions, with evaluations using k-nearest-neighbor classifiers.",0],[-7.7060213089,-1.3624186516,"title: Podium: Ranking Data Using Mixed-Initiative Visual Analytics, abstract: People often rank and order data points as a vital part of making decisions. Multi-attribute ranking systems are a common tool used to make these data-driven decisions. However, these systems assume that users are able to quantify their conceptual understanding of how important particular attributes are to a decision, which is not always easy or even possible for users to do. To address these challenges, we present a visual analytic application to help people rank multi-variate data points. We developed a prototype system, Podium, that allows users to drag rows in the table to rank order data points based on their perception of the relative value of the data. Podium then infers a weighting model using Ranking SVM that satisfies the user\u2019s data preferences as closely as possible., authors: [{'name': 'Emily Wall', 'affiliation': 'Georgia Institute of Technology, Atlanta, GA, USA'}, {'name': 'Subhajit Das', 'affiliation': 'Georgia Institute of Technology, Atlanta, GA, USA'}, {'name': 'Ravish Chawla', 'affiliation': 'Georgia Institute of Technology, Atlanta, GA, USA'}, {'name': 'Bharath Kalidindi', 'affiliation': 'Georgia Institute of Technology, Atlanta, GA, USA'}, {'name': 'Eli T. Brown', 'affiliation': 'DePaul University, Chicago, IL, USA'}, {'name': 'Alex Endert', 'affiliation': 'Georgia Institute of Technology, Atlanta, GA, USA'}], publicationVenue: IEEE Transactions on Visualization and Computer Graphics, publicationDate: Not specified, keywords: ['Mixed-initiative visual analytics', 'multi-attribute ranking', 'user interaction'], theoreticalFramework: The research is grounded in the understanding that users often have a holistic understanding of data rather than a detailed comprehension of individual attributes' importance. It leverages mixed-initiative visual analytics to balance human and machine effort in data analysis., mainPoints: ['Introduction of Podium, a prototype system for ranking multi-variate data points based on user perception.', \"Use of Ranking SVM to infer weighting models that reflect users' data preferences.\", \"Demonstration of Podium's application through usage scenarios.\", 'Discussion on the balance of human and machine effort in visual analytics.'], results: The system was able to infer attribute weights that closely matched users' implicit preferences, allowing for a deeper understanding of the attributes that inform their understanding of the data., applications: ['Understanding which attributes contribute to a user\u2019s subjective preferences for data.', 'Deconstructing attributes of importance for existing rankings.'], additionalInformation: ['The approach makes powerful machine learning techniques more usable to those without expertise in these areas.', 'Future work could explore alternative interfaces for making relative comparisons and other models for determining attribute weight vectors.', 'The system currently relies on purely numerical data, with potential future extensions to handle categorical data.'], methodology.dataCollection: User interactions with the Podium interface, specifically dragging rows to indicate preferred data point rankings., methodology.dataAnalysis: Application of Ranking SVM to generate attribute weights based on user-defined rankings, and subsequent ranking of the full dataset using these weights.",0],[-7.7856726646,-1.338537693,"title: Bridging the Gap between User Intention and Model Parameters for Human-in-the-Loop Data Analytics, abstract: Exploratory data analysis is challenging given the complexity of data. Models find structure in the data lessening the complexity for users. These models have parameters that can be adjusted to explore the data from many different angles providing more ways to learn about the data. \u201cHuman in the loop\u201d means users can interact with the parameters to explore alternative structures. This exploration allows for discovery. This paper examines usability issues of Human-Model Interaction (HMI) for data analytics. In particular, we bridge the gaps between a user\u2019s intention and the parameters of a WMDS model during HMI communication., authors: [{'name': 'Jessica Zeitz Self', 'affiliation': 'Discovery Analytics Center, Virginia Tech, Blacksburg, VA'}, {'name': 'Radha Krishnan Vinayagam', 'affiliation': 'Discovery Analytics Center, Virginia Tech, Blacksburg, VA'}, {'name': 'J.T. Fry', 'affiliation': 'Discovery Analytics Center, Virginia Tech, Blacksburg, VA'}, {'name': 'Chris North', 'affiliation': 'Discovery Analytics Center, Virginia Tech, Blacksburg, VA'}], publicationVenue: HILDA\u201916, June 26, 2016, San Francisco, CA, USA, publicationDate: June 26, 2016, keywords: ['Visual analytics', 'object-level interaction', 'usability'], theoreticalFramework: The research is grounded in the theoretical framework of Human-Model Interaction (HMI), focusing on the interaction design problems arising from the gap between user intentions and model parameters, particularly in the context of Weighted Multidimensional Scaling (WMDS) for high-dimensional data analytics., mainPoints: ['Exploration of usability issues in the context of Weighted Multidimensional Scaling (WMDS) for high-dimensional data analytics.', 'Identification of usability problems in interacting with WMDS.', 'Creation and evaluation of interaction design solutions for these problems.'], results: The designed interaction solutions, including object-level interaction and dynamic updating, effectively bridged the gap between user intentions and model parameters, leading to an improved usability score (SUS) of 81.78, indicating above-average usability., applications: ['Enhancing the usability of data analytics tools for non-expert users.', 'Improving the effectiveness of exploratory data analysis through intuitive interaction designs.'], additionalInformation: ['The study highlights the importance of aligning user cognitive models with mathematical models in data analytics tools.', 'Future research directions include further refinement of interaction designs and exploration of other data analytics models beyond WMDS.', 'The research contributes to the field by demonstrating how interaction design can mitigate usability issues in human-in-the-loop data analytics.'], methodology.dataCollection: A quasi-empirical usability study with seven graduate students exploring a high-dimensional dataset about 49 animals and 36 dimensions., methodology.dataAnalysis: Analysis of user interactions with the WMDS model, focusing on the effectiveness of designed interaction solutions in bridging the gap between user intentions and model parameters.",0],[-7.9931049347,-0.620742321,"title: Big Text Visual Analytics in Sensemaking, abstract: Learning from text data often involves a loop of tasks that iterate between foraging for information and synthesizing it in incremental hypotheses. This paper addresses the challenge of using spatial workspaces for synthesizing information from large document collections, particularly when only a small subset are relevant. The multi-model semantic interaction (MSI) technique is applied, leveraging user interactions to aid in display layout, forage for new, relevant documents as implied by the interactions, and place them in context of the user\u2019s existing spatial layout., authors: [{'name': 'Lauren Bradel', 'affiliation': 'Department of Computer Science, Virginia Tech'}, {'name': 'Nathan Wycoff', 'affiliation': 'Department of Computer Science, Virginia Tech'}, {'name': 'Leanna House', 'affiliation': 'Department of Statistics, Virginia Tech'}, {'name': 'Chris North', 'affiliation': 'Department of Computer Science, Virginia Tech'}], publicationVenue: IEEE, publicationDate: 2015, keywords: ['sensemaking', 'interaction design', 'visual analytics'], theoreticalFramework: The research is grounded in the theory of sensemaking in large text data analytics, emphasizing the importance of spatial workspaces and semantic interaction for information synthesis., mainPoints: ['Spatial workspaces facilitate the synthesis of information from large text datasets.', 'The multi-model semantic interaction technique leverages user interactions for layout adjustments, document foraging, and contextual placement.', 'Semantic interaction embeds visual analytics of big text collections directly into the human sensemaking process.'], results: The application of multi-model semantic interaction enables effective sensemaking in large text datasets by integrating information retrieval with information synthesis in a spatial workspace, demonstrating the system's capability through use cases like literature review and investigative journalism., applications: ['Literature review in academic research.', 'Investigative journalism for exploring current events and news topics.'], additionalInformation: ['The system faces limitations in parsing all documents at once and integrating with external information retrieval algorithms.', 'Future work includes improving the retrieval and parsing process, exploring additional recommender systems, and extending the system to cache potential results for future relevance.', 'This research contributes to the field by demonstrating the practical application of semantic interaction in real-world exploratory data analysis tasks.'], methodology.dataCollection: The study uses large document collections such as scientific literature, news, and web data as the basis for analysis., methodology.dataAnalysis: Semantic interaction techniques are applied to interpret user interactions for data layout, relevance filtering, and similarity-based spatial arrangement.",2],[-8.3798122406,-1.3249205351,"title: iLAMP: Exploring High-Dimensional Spacing through Backward Multidimensional Projection, abstract: This paper presents iLAMP, an inverse linear affine multidimensional projection technique for interactive exploration of multidimensional data. It operates in reverse to traditional projection methods by mapping low-dimensional information into a high-dimensional space, enabling users to extrapolate instances of a multidimensional dataset while exploring a projection of the data to the planar domain., authors: [{'name': 'Elisa Portes dos Santos Amorim', 'affiliation': 'University of Calgary'}, {'name': 'Emilio Vital Brazil', 'affiliation': 'University of Calgary'}, {'name': 'Joel Daniels II', 'affiliation': 'NYU Polytechnic Institute'}, {'name': 'Paulo Joia', 'affiliation': 'University of Sao Paulo'}, {'name': 'Luis Gustavo Nonato', 'affiliation': 'University of Sao Paulo'}, {'name': 'Mario Costa Sousa', 'affiliation': 'University of Calgary'}], publicationVenue: IEEE Symposium on Visual Analytics Science and Technology 2012, publicationDate: October 14 - 19, Seattle, WA, USA, keywords: ['High-dimensional data exploration', 'Multidimensional projection', 'iLAMP', 'Data visualization', 'Interactive exploration'], theoreticalFramework: The research is grounded in the challenges of exploring and understanding high-dimensional data spaces. It builds upon the concept of multidimensional projection, particularly focusing on the inverse process of mapping low-dimensional projections back to high-dimensional spaces., mainPoints: ['Introduction of iLAMP, a novel technique for interactive exploration of high-dimensional data.', 'iLAMP operates by mapping low-dimensional projections back to high-dimensional spaces, enabling data extrapolation.', 'Experimental validation of iLAMP demonstrates its effectiveness in accurately mapping projections and exploring data.', 'Application of iLAMP in optimizing high-dimensional parameter spaces, showcasing its practical utility.'], results: iLAMP was shown to accurately map low-dimensional projections back to high-dimensional spaces, preserving distances and relationships. It enabled effective exploration and extrapolation of high-dimensional data, demonstrating potential for enhancing optimization processes., applications: ['Interactive exploration and visualization of high-dimensional datasets across various fields.', 'Enhancing optimization algorithms by allowing users to explore and resample parameter spaces interactively.'], additionalInformation: ['The study highlights the importance of user interaction in exploring high-dimensional spaces and suggests iLAMP as a tool to incorporate user intuition into data analysis processes.', 'Future research directions include automating the selection of the number of neighbors (k) in iLAMP and integrating traditional visualization techniques for deeper insights.', 'The paper contributes to the field by providing a novel method for backward multidimensional projection, expanding the toolkit available for high-dimensional data exploration.'], methodology.dataCollection: Synthetic and manufactured datasets were used to validate the iLAMP technique., methodology.dataAnalysis: iLAMP's effectiveness was measured through experiments assessing the quality and coherence of the extrapolated data, using metrics such as distance to surface, stress function, and LAMP-validation.",0],[-7.857896328,-1.2261800766,"title: Observation-Level Interaction with Clustering and Dimension Reduction Algorithms, abstract: This paper introduces a model for Observation-Level Interaction (OLI) that integrates clustering within data projections to enhance sensemaking in visual analytics. By allowing users to interactively manipulate data points and clusters in a visualization, the model provides a cooperative framework where user actions inform the underlying mathematical model, affecting both the data layout and cluster formations. This approach addresses the OLI 'with respect to what' problem by using clusters as interaction targets, thereby refining the feedback loop between user intentions and the visualization layout., authors: [{'name': 'John Wenskovitch', 'affiliation': 'Discovery Analytics Center, Virginia Tech, Blacksburg, VA'}, {'name': 'Chris North', 'affiliation': 'Discovery Analytics Center, Virginia Tech, Blacksburg, VA'}], publicationVenue: HILDA '17 Chicago, Illinois, USA, publicationDate: 2017, keywords: ['Observation-Level Interaction (OLI)', 'sensemaking', 'data clustering', 'semantic interaction', 'visual analytics'], theoreticalFramework: The research is grounded in the concept of Observation-Level Interaction (OLI), which emphasizes the role of interactive semantic exploration in sensemaking processes. The framework integrates clustering and dimension reduction techniques to enhance user interaction with multidimensional data projections., mainPoints: ['Introduction of a model that integrates clustering within data projections for enhanced sensemaking.', 'Proposal of a cooperative framework where user interactions with data points and clusters inform the underlying mathematical model.', \"Addressing the OLI 'with respect to what' problem by using clusters as explicit targets for interaction.\", 'Evaluation of the model through a case study involving a dataset of animal characteristics.'], results: The model successfully learns from user interactions, affecting the layout of nodes and clusters not directly interacted with by the user. The case study demonstrates the model's ability to adapt to user intentions, refining the visualization to better reflect user-defined relationships among data points., applications: ['Enhancing visual analytics tools with interactive clustering and dimension reduction capabilities.', 'Improving sensemaking in complex data exploration tasks by providing a more intuitive interaction model.'], additionalInformation: ['The system initializes with predetermined cluster settings, which may introduce bias in user exploration.', 'Future work includes exploring high-dimensional space clustering before projection, supporting cluster-level interactions, and updating the backend model for true layout model inversion.', 'The research highlights the importance of integrating user feedback into the visualization process for more meaningful data exploration.'], methodology.dataCollection: Use of a dataset containing 49 animals defined by 85 numeric attributes for the case study., methodology.dataAnalysis: Application of Euclidean distance function, force-directed layout, and k-means clustering to project and cluster the data. User interactions are then used to iteratively refine the model based on the manipulation of data points and clusters.",0],[-8.0859203339,-1.173468709,"title: Designing for Interactive Dimension Reduction Visual Analytics Tools to Explore High-Dimensional Data, abstract: Exploring high-dimensional data is challenging. This paper presents principles for developing interactive visual analytic systems that enable users to tweak model parameters directly or indirectly to explore high-dimensional data. An application implementing interactive weighted multidimensional scaling (WMDS), Andromeda, is introduced to exemplify these principles., authors: [{'name': 'Jessica Zeitz Self', 'affiliation': 'Not specified'}, {'name': 'Xinran Hu', 'affiliation': 'Not specified'}, {'name': 'Leanna House', 'affiliation': 'Not specified'}, {'name': 'Scotland Leman', 'affiliation': 'Not specified'}, {'name': 'Chris North', 'affiliation': 'Not specified'}], publicationVenue: Not specified, publicationDate: Not specified, keywords: ['Dimensionality reduction', 'Object-level interaction', 'Visual analytics', 'Interface design'], theoreticalFramework: The research is grounded in the challenges of exploring high-dimensional data and the potential of dimension reduction algorithms, such as multidimensional scaling, to support data explorations by reducing datasets to two dimensions for visualization., mainPoints: ['High-dimensional data exploration is challenging and requires effective tools.', 'Dimension reduction algorithms can support data explorations by reducing datasets to two dimensions.', 'Interactive visual analytic systems can enable users to explore high-dimensional data by tweaking model parameters.', 'Andromeda, an application implementing interactive WMDS, allows for both parametric and object-level interaction for in-depth data exploration.', 'Design principles for effective interactive visual analytic tools focus on layout, semantically visualizing parameters, and designing the communication between the interface and the algorithm.'], results: The final version of Andromeda resulted from sequential improvements and user critiques, uncovering design principles for interactive visual analytics tools. Users were able to perform new tasks and gain complex insights through the combination of parametric interaction and object-level interaction., applications: ['Exploration of high-dimensional data in various fields such as education, research, and data science.', 'Enhancement of user data exploration techniques through interactive dimension reduction visual analytics tools.'], additionalInformation: ['The study emphasizes the importance of both parametric interaction and object-level interaction for effective data exploration.', 'Future research directions could explore the application of these principles to other dimension reduction models.', 'Key contributions include the development of design principles for interactive visual analytics tools and the demonstration of these principles through the Andromeda interface.'], methodology.dataCollection: Sequential improvements made to multiple designs critiqued by users, and application in education settings with graduate level courses., methodology.dataAnalysis: Analysis of insights and processes from user critiques and course applications to uncover design principles.",0],[-8.0248632431,-1.2136560678,"title: Andromeda: Observation-Level and Parametric Interaction for Exploratory Data Analysis, abstract: Exploring high-dimensional data is challenging. As the number of dimensions in datasets increases, it becomes harder to discover patterns and develop insights. Dimension reduction algorithms, such as multidimensional scaling, support data explorations by reducing datasets to two dimensions for visualization. Because these algorithms rely on underlying parameterizations, they may be tweaked to assess the data from multiple perspectives. Alas, tweaking can be difficult for users without a strong knowledge base of the underlying algorithms. We present Andromeda, an interactive visual analytics tool we developed to enable non-experts of statistical models to explore domain-specific, high-dimensional data. This application implements interactive weighted multidimensional scaling (WMDS) and allows for both parametric and observation-level interaction to provide in-depth data exploration., authors: [{'name': 'Jessica Zeitz Self', 'affiliation': 'Virginia Tech, Blacksburg, USA'}, {'name': 'Leanna House', 'affiliation': 'Virginia Tech, Blacksburg, USA'}, {'name': 'Scotland Leman', 'affiliation': 'Virginia Tech, Blacksburg, USA'}, {'name': 'Chris North', 'affiliation': 'Virginia Tech, Blacksburg, USA'}], publicationVenue: Not specified, publicationDate: Not specified, keywords: ['Evaluation', 'user interface', 'dimension reduction', 'usability'], theoreticalFramework: The research is grounded in the challenges of exploring high-dimensional data and the utility of dimension reduction algorithms like weighted multidimensional scaling (WMDS) for visualization and data exploration., mainPoints: ['High-dimensional data exploration is challenging and essential for discovering patterns and insights.', 'Dimension reduction algorithms facilitate data exploration by reducing datasets to two dimensions for visualization.', 'Andromeda is an interactive visual analytics tool designed for non-experts to explore high-dimensional data using WMDS.', 'Andromeda supports both parametric interaction and observation-level interaction, enhancing data exploration capabilities.', 'A controlled usability study was conducted to assess Andromeda and compare the effectiveness of parametric interaction, observation-level interaction, and their combination.'], results: Participants were able to effectively use Andromeda for data exploration, regardless of the interaction type provided. The study showed that both parametric interaction and observation-level interaction are necessary for a complete analysis, with each type of interaction being more suitable for different kinds of tasks., applications: ['Enabling non-experts to explore and analyze high-dimensional data without deep knowledge of statistical models.', 'Facilitating educational purposes by helping students understand complex data analysis concepts through interactive exploration.', 'Supporting domain experts in various fields to discover patterns and insights in their specific high-dimensional datasets.'], additionalInformation: ['The study highlights the importance of combining parametric interaction and observation-level interaction for comprehensive data analysis.', 'Future research directions include exploring other dimension reduction algorithms and interaction techniques to enhance data exploration.', 'The research contributes to the field by demonstrating the usability and effectiveness of Andromeda in facilitating exploratory data analysis for non-experts.'], methodology.dataCollection: A controlled usability study with participants from various disciplines exploring a high-dimensional dataset about animals., methodology.dataAnalysis: Analysis of participants' ability to perform tasks, generate insights, and understand WMDS concepts using Andromeda with different interaction capabilities.",0],[-8.2874574661,-1.2711070776,"title: Casting Multiple Shadows: High-Dimensional Interactive Data Visualisation with Tours and Embeddings, abstract: Non-linear dimensionality reduction (NLDR) methods such as t-distributed stochastic neighbour embedding (t-SNE) are ubiquitous in the natural sciences, however, the appropriate use of these methods is difficult because of their complex parameterisations; analysts must make trade-offs in order to identify structure in the visualisation of an NLDR technique. We present visual diagnostics for the pragmatic usage of NLDR methods by combining them with a technique called the tour. A tour is a sequence of interpolated linear projections of multivariate data onto a lower dimensional space. The sequence is displayed as a dynamic visualisation, allowing a user to see the shadows the high-dimensional data casts in a lower dimensional view. By linking the tour to an NLDR view, we can preserve global structure and through user interactions like linked brushing observe where the NLDR view may be misleading., authors: [{'name': 'Stuart Lee', 'affiliation': 'Monash University'}, {'name': 'Ursula Laa', 'affiliation': 'Monash University'}, {'name': 'Dianne Cook', 'affiliation': 'Monash University'}], publicationVenue: Journal of Data Science, Statistics, and Visualisation, publicationDate: December 2020, keywords: ['dimensionality reduction', 'high-dimensional data', 'interactive graphics', 't-SNE', 'grand tour', 'R'], theoreticalFramework: The paper is grounded in the theory of dimensionality reduction, particularly focusing on non-linear dimensionality reduction (NLDR) methods and the concept of the tour for high-dimensional data visualization., mainPoints: ['NLDR methods are widely used but challenging due to complex parameterizations.', 'The tour technique offers a dynamic visualization of high-dimensional data in lower dimensions.', 'Combining NLDR methods with tours can help preserve global structure and identify misleading aspects of NLDR visualizations.', 'The implementation of this framework is available as an R package called liminal.'], results: The approach is shown to be useful for cluster orientation tasks and helps in identifying distortions and diffusions in NLDR visualizations, making it easier for analysts to interpret high-dimensional data., applications: ['Enhancing the interpretability of NLDR visualizations in natural sciences.', 'Assisting in cluster orientation tasks in data analysis workflows.', 'Providing a pragmatic workflow for incorporating interactive graphics and tours with embeddings.'], additionalInformation: ['The framework is implemented in an R package called liminal, available on GitHub.', 'The study highlights the importance of visual diagnostics in the use of NLDR methods.', 'Future research directions could include exploring one to many linked brushing for investigating neighbourhood preservation and developing better displays and sub-sampling strategies for large datasets.'], methodology.dataCollection: The study uses both simulated datasets and real-world single cell transcriptomics data to demonstrate the application of the proposed framework., methodology.dataAnalysis: The analysis involves combining NLDR methods with the tour technique, using interactive graphics for data visualization, and employing case studies to illustrate the utility of the approach.",0],[-7.8670368195,-1.2055789232,"title: Bridging cognitive gaps between user and model in interactive dimension reduction, abstract: Interactive machine learning (ML) systems are difficult to design because of the \u2018Two Black Boxes\u2019 problem that exists at the interface between human and machine. This paper identifies several cognitive gaps in a previously-developed interactive visual analytics (VA) system, Andromeda, and aims to bridge these gaps by making usability improvements. The improvements include designing new visual features and improving the underlying algorithm to better implement user intent during data exploration. The improved Andromeda system is evaluated through qualitative and quantitative analysis, confirming its enhanced performance in high-dimensional data analysis tasks., authors: [{'name': 'Ming Wang', 'affiliation': 'Virginia Tech, Computer Science, United States of America'}, {'name': 'John Wenskovitch', 'affiliation': 'Virginia Tech, Computer Science, United States of America; Pacific Northwest National Laboratory (PNNL), United States of America'}, {'name': 'Leanna House', 'affiliation': 'Virginia Tech, Statistics, United States of America'}, {'name': 'Nicholas Polys', 'affiliation': 'Virginia Tech, Computer Science, United States of America'}, {'name': 'Chris North', 'affiliation': 'Virginia Tech, Computer Science, United States of America'}], publicationVenue: Visual Informatics, publicationDate: 2021, keywords: ['Interactive machine learning', 'Visual analytics', 'Dimension reduction', 'Usability', 'Cognitive gaps'], theoreticalFramework: The research is guided by the 'Two Black Boxes' problem, focusing on the communication challenges between humans and algorithms in interactive ML systems., mainPoints: ['Identification of cognitive gaps in the Andromeda visual analytics system.', 'Design and implementation of usability improvements to bridge these gaps.', 'Evaluation of the improved system through qualitative and quantitative analysis.'], results: The improved Andromeda system demonstrated enhanced performance in high-dimensional data analysis tasks, with usability improvements effectively bridging the identified cognitive gaps., applications: ['Enhanced user understanding and interaction with interactive machine learning systems.', 'Improved design of visual analytics tools for high-dimensional data exploration.'], additionalInformation: [\"The study highlights the importance of addressing the 'Two Black Boxes' problem in interactive ML systems.\", 'Future research directions include exploring additional dimension-related features and improving the random sampling strategy for clustering.', 'The research contributes to the field by providing insights into designing more usable and effective interactive visual analytics tools.'], methodology.dataCollection: Usability study with participants exploring a dataset using two versions of Andromeda, and simulation analysis for the random sampling solution., methodology.dataAnalysis: Qualitative and quantitative analysis of user performance and system efficiency in data exploration tasks.",0],[-8.6664457321,-0.482925117,"title: Visualizing Hidden Themes of Taxi Movement with Semantic Transformation, abstract: A new methodology is developed to discover and analyze the hidden knowledge of massive taxi trajectory data within a city. This approach creatively transforms the geographic coordinates (i.e., latitude and longitude) to street names reflecting contextual semantic information, enabling semantic analysis of massive taxi data sets as document corpora. Hidden themes, namely taxi topics, are identified through textual topic modeling techniques and visualized through a visual analytics system integrating interactive visualization tools., authors: [{'name': 'Ding Chu', 'affiliation': 'Kent State University'}, {'name': 'David A. Sheets', 'affiliation': 'Kent State University'}, {'name': 'Ye Zhao', 'affiliation': 'Kent State University'}, {'name': 'Yingyu Wu', 'affiliation': 'Kent State University'}, {'name': 'Jing Yang', 'affiliation': 'UNC Charlotte'}, {'name': 'Maogong Zheng', 'affiliation': 'Shenzhen Institute of Advanced Technologies'}, {'name': 'George Chen', 'affiliation': 'Shenzhen Institute of Advanced Technologies'}], publicationVenue: 2014 IEEE Pacific Visualization Symposium, publicationDate: 2014, keywords: ['Taxi Trajectories', 'Semantic Transformation', 'Clustering', 'Topic Modeling', 'Latent Dirichlet Analysis'], theoreticalFramework: The research is guided by the theoretical framework of semantic transformation of spatial data into textual format, enabling the application of text analysis techniques such as Latent Dirichlet Allocation (LDA) for uncovering hidden patterns in taxi movement data., mainPoints: ['Introduction of a novel methodology for analyzing taxi trajectory data by transforming geographic coordinates into street names.', 'Application of textual topic modeling techniques to identify hidden themes in taxi movements.', 'Development of a visual analytics system integrating various interactive visualization tools for exploring the identified taxi topics.'], results: The methodology successfully identifies and visualizes hidden themes in taxi movements, reflecting urban mobility patterns. The visual analytics system allows for effective exploration of these patterns, demonstrating the approach's effectiveness through case studies., applications: ['Urban planning and traffic management by understanding taxi movement patterns.', 'Enhancing public transportation systems by identifying high-demand areas.', 'Providing insights for taxi drivers and companies for optimizing routes and improving service efficiency.'], additionalInformation: ['The study introduces a novel approach to processing and analyzing massive sets of taxi trajectory data.', 'Future research directions include investigating advanced LDA models and integrating more visualization techniques.', 'The study highlights the potential of semantic transformation and topic modeling in uncovering complex urban mobility patterns.'], methodology.dataCollection: The study uses daily trajectories of 21,360 taxis in Shenzhen, China, including GPS sample positions and metadata such as time, speed, and occupancy status., methodology.dataAnalysis: Semantic transformation of GPS data to street names, followed by the application of Latent Dirichlet Allocation (LDA) to infer hidden taxi movement patterns and visualize them through a prototype system named VATT (Visual Analytics of Taxi Topics).",-1],[-8.0668411255,-0.3150778413,"title: SemVis: Semantic Visualization for Interactive Topical Analysis, abstract: Exploratory analysis of a text corpus is an important task that can be aided by informative visualization. Semantic visualization infuses the visualization space with latent semantics by incorporating a topic model, allowing users to perceive relationships between documents and topics spatially. This paper illustrates how a semantic visualization system called SemVis could be used to navigate a text corpus interactively and topically via browsing and searching., authors: [{'name': 'Tuan M. V. Le', 'affiliation': 'Singapore Management University, 80 Stamford Road, Singapore 178902'}, {'name': 'Hady W. Lauw', 'affiliation': 'Singapore Management University, 80 Stamford Road, Singapore 178902'}], publicationVenue: CIKM\u201917, November 6\u201310, 2017, Singapore, publicationDate: 2017, keywords: ['Semantic visualization', 'topic model', 'interactive topical analysis'], theoreticalFramework: The research is grounded in the concept of semantic visualization, which integrates topic modeling with spatial visualization techniques to represent text corpora. It leverages the idea that spatial proximity in the visualization can reflect semantic closeness, enhancing the exploratory analysis of text data., mainPoints: ['Introduction of SemVis, a semantic visualization system for interactive topical analysis.', 'Discussion on the importance of semantic visualization in understanding text corpora.', 'Illustration of how SemVis enables browsing and searching of a text corpus through a spatially-oriented interface.', 'Presentation of a pilot user study confirming the effectiveness of SemVis in aiding users to perceive document similarities and topics.'], results: The pilot user study showed that semantic visualization, as implemented in SemVis, helps users achieve better precision, recall, and F1 scores in identifying documents related to specific topics, compared to traditional scatterplot visualizations generated from t-SNE., applications: ['Interactive exploration and analysis of text corpora for various professional scenarios, such as literature review and legal research.', 'Enhanced understanding of text data through spatially-oriented visualization, facilitating the discovery of document similarities and topic distributions.'], additionalInformation: ['SemVis is the first demonstrable semantic visualization system, setting a precedent for future research and development in the field.', 'The study highlights the importance of incorporating topic information (colors and representative words) in the visualization to aid user comprehension.', 'Future research directions include exploring other datasets, refining the visualization techniques, and further user studies to validate the effectiveness of semantic visualization in various contexts.'], methodology.dataCollection: The methodology involves using existing text corpora, such as the 20News dataset, for demonstration and evaluation purposes., methodology.dataAnalysis: Semantic visualization techniques, specifically the Semafore model, are used to jointly model topics and visualization coordinates. This includes the generation of document and topic coordinates, and the visualization of these elements within a 2D scatterplot.",2],[-8.128194809,-0.3649409711,"title: From paragraph to graph: Latent semantic analysis for information visualization, abstract: This paper discusses the use of Latent Semantic Analysis (LSA) as an effective dimension reduction method for visualizing textual information. It highlights the limitations of traditional methods that rely on intellectually created links and proposes the use of LSA to explore high-dimensional semantic spaces through dynamic visualizations., authors: [{'name': 'Thomas K. Landauer', 'affiliation': 'Department of Psychology, University of Colorado, Boulder, CO'}, {'name': 'Darrell Laham', 'affiliation': 'Knowledge Analysis Technologies, Boulder, CO'}, {'name': 'Marcia Derr', 'affiliation': 'Knowledge Analysis Technologies, Boulder, CO'}], publicationVenue: PNAS, publicationDate: April 6, 2004, keywords: ['Latent Semantic Analysis', 'Information Visualization', 'Dimension Reduction', 'Semantic Space', 'Textual Information'], theoreticalFramework: The paper is grounded in the theory that semantic content of documents can be effectively represented and explored through dimension reduction techniques like LSA, which reflects synonymy and the sense of arbitrary word combinations., mainPoints: ['LSA provides an effective method for dimension reduction in textual information visualization.', 'Traditional methods based on intellectually created links have limitations in capturing the semantic content of documents.', 'High-dimensional dynamic viewers with effective projection pursuit routines can reveal multiple informative views missed by computational algorithms.', \"The human visual system's ability to extract information from moving patterns is leveraged in LSA-based visualizations.\"], results: The study demonstrates the potential of LSA in creating dynamic visualizations that allow for the exploration of semantic relationships in textual data, showing examples of visualizations that could support various analytical tasks., applications: ['Improving information retrieval by visualizing document similarities beyond keyword overlap.', 'Supporting research by identifying related works across different dimensions of similarity.', 'Aiding in the organization and analysis of scientific literature by visualizing the semantic content of documents.'], additionalInformation: ['The study suggests that linguistic meaning is intrinsically high-dimensional, challenging the effectiveness of reducing information to two or three dimensions for visualization.', 'Future research directions include improving the user interface for LSA-based visualizations and exploring automatic methods for identifying informative views.', 'The paper highlights the importance of user testing in developing effective information visualization tools.'], methodology.dataCollection: The study applied LSA to a corpus of documents from PNAS volumes 94\u201399, creating a 300-dimensional semantic space., methodology.dataAnalysis: Visualization techniques, including projection pursuit and user-guided exploration, were used to explore and identify informative views in the high-dimensional space created by LSA.",2],[-8.1434860229,-0.6592284441,"title: Semantic Interaction for Visual Text Analytics, abstract: Visual analytics emphasizes sensemaking of large, complex datasets through interactively exploring visualizations generated by statistical models. This paper presents the concept of semantic interaction, enabling analysts to interact with models directly within the visual metaphor using interactions that derive from their analytic process, such as searching, highlighting, annotating, and repositioning documents. The implementation of semantic interactions using machine learning techniques in a visual analytic tool, ForceSPIRE, for interactive analysis of textual data within a spatial visualization is demonstrated., authors: [{'name': 'Alex Endert', 'affiliation': 'Virginia Tech, Blacksburg, VA USA'}, {'name': 'Patrick Fiaux', 'affiliation': 'Virginia Tech, Blacksburg, VA USA'}, {'name': 'Chris North', 'affiliation': 'Virginia Tech, Blacksburg, VA USA'}], publicationVenue: CHI 2012, publicationDate: May 5\u201310, 2012, keywords: ['Visualization', 'visual analytics', 'interaction'], theoreticalFramework: The paper is grounded in the theoretical framework of visual analytics, emphasizing the integration of human intuition with statistical models and visualization for sensemaking in large, complex datasets. It introduces semantic interaction as a means to bridge the gap between user interaction and statistical model adaptation., mainPoints: ['Introduction of semantic interaction for visual text analytics.', 'Demonstration of semantic interaction through the ForceSPIRE visual analytic tool.', 'Discussion on how semantic interaction enables direct manipulation of the visualization to guide underlying models.', 'Presentation of a use case to illustrate the application of semantic interaction in uncovering hidden patterns in textual data.'], results: The implementation of semantic interaction within ForceSPIRE demonstrated that users could effectively guide the visualization and underlying model through direct interaction, facilitating the sensemaking process and uncovering hidden patterns in the data., applications: ['Enhancing visual text analytics tools with semantic interaction capabilities.', 'Improving sensemaking in large, complex datasets by allowing analysts to directly manipulate visualizations.', 'Facilitating the exploration of textual data through intuitive user interactions.'], additionalInformation: ['The study highlights the importance of integrating user interactions into the model adaptation process for visual analytics.', 'Future research directions include exploring other forms of semantic interaction and evaluating the effectiveness of semantic interaction in various analytical tasks.', 'The paper contributes to the field by proposing a novel approach to interaction in visual analytics, emphasizing the role of user input in guiding the analysis process.'], methodology.dataCollection: Use of textual document collections and user interactions (searching, highlighting, annotating, repositioning) as data for analysis., methodology.dataAnalysis: Implementation of machine learning techniques to adapt the visualization based on user interactions, modifying the underlying statistical model to reflect the analyst's reasoning.",2],[-8.4184932709,-0.0309897754,"title: Interpretive Impacts of Text Visualization: Mitigating Political Framing Effects, abstract: This article explores how text visualization can influence the impacts that framing has on the perception of political issues. It demonstrates that exposure to a text visualization can mitigate framing effects and shows a transfer effect, where participants who saw the visualization remained uninfluenced by framing in subsequent texts, even when the visualization was absent., authors: [{'name': 'Eric P. S. Baumer', 'affiliation': 'Lehigh University'}, {'name': 'Jaime Snyder', 'affiliation': 'University of Washington'}, {'name': 'Geri K. Gay', 'affiliation': 'Cornell University'}], publicationVenue: ACM Transactions on Computer-Human Interaction, publicationDate: August 2018, keywords: ['Text visualization', 'visualization design', 'political framing effects', 'cognitive and interpretive mechanisms', 'interactive text visualization'], theoreticalFramework: The study is grounded in communicative and cognitive theories, particularly focusing on how framing effects occur and can be mitigated through visual representations of text., mainPoints: ['Text visualizations can mitigate the effects of political framing on issue perception.', 'A transfer effect was observed where the mitigation of framing effects persisted in subsequent texts without visualizations.', 'The study suggests that visualizations can prime more deliberate cognitive processes, reducing susceptibility to framing effects.'], results: Both word cloud and word web visualizations were effective in mitigating framing effects, with significant interactions observed between visualization conditions and political ideology in shaping opinions on national healthcare., applications: ['Designing information visualization systems for political and social issues to promote critical thinking and reduce subconscious biases.', 'Educational tools to enhance media literacy by illustrating the influence of framing in political communication.'], additionalInformation: ['The study highlights the importance of evaluating visualizations in communicative contexts beyond task performance.', 'Future research directions include exploring the duration of transfer effects and the impact of visualizations on other subconscious processes.', 'The study contributes to understanding the role of visualizations in mediating cognitive and interpretive processes in reading text.'], methodology.dataCollection: Controlled laboratory study with participants exposed to political texts with varying frames and visualizations., methodology.dataAnalysis: Analysis involved comparing participants' perceptions and opinions across different visualization conditions to assess the impact on framing effects.",-1],[-8.377199173,-0.8556438088,"title: AI4VIS: Survey on Artificial Intelligence Approaches for Data Visualization, abstract: Visualizations themselves have become a data format. Akin to other data formats such as text and images, visualizations are increasingly created, stored, shared, and (re-)used with artificial intelligence (AI) techniques. In this survey, we probe the underlying vision of formalizing visualizations as an emerging data format and review the recent advance in applying AI techniques to visualization data (AI4VIS). We define visualization data as the digital representations of visualizations in computers and focus on data visualization (e.g., charts and infographics). We build our survey upon a corpus spanning ten different fields in computer science with an eye toward identifying important common interests. Our resulting taxonomy is organized around WHAT is visualization data and its representation, WHY and HOW to apply AI to visualization data., authors: [{'name': 'Aoyu Wu', 'affiliation': 'Hong Kong University of Science and Technology'}, {'name': 'Yun Wang', 'affiliation': 'Microsoft Research Asia'}, {'name': 'Xinhuan Shu', 'affiliation': 'Hong Kong University of Science and Technology'}, {'name': 'Dominik Moritz', 'affiliation': 'Carnegie Mellon University and Apple'}, {'name': 'Weiwei Cui', 'affiliation': 'Microsoft Research Asia'}, {'name': 'Haidong Zhang', 'affiliation': 'Microsoft Research Asia'}, {'name': 'Dongmei Zhang', 'affiliation': 'Microsoft Research Asia'}, {'name': 'Huamin Qu', 'affiliation': 'Hong Kong University of Science and Technology'}], publicationVenue: IEEE Transactions on Visualization and Computer Graphics, publicationDate: December 2022, keywords: ['Survey', 'data visualization', 'artificial intelligence', 'data format', 'machine learning'], theoreticalFramework: The research is guided by the vision of formalizing visualizations as a new data format and explores the application of AI techniques in managing and exploiting visualization data., mainPoints: ['Visualizations are becoming a new data format processed by AI.', 'A taxonomy is developed to categorize AI4VIS research into what, why, and how perspectives.', 'Common tasks applied to visualization data are identified and discussed.', 'Research opportunities in managing and exploiting visualization data with AI support are outlined.'], results: The survey synthesizes the current landscape of AI4VIS research, identifying common tasks and techniques across disciplines. It also highlights the need for more research in managing and exploiting visualization data with AI., applications: ['Automating the creation of visualizations', 'Enhancing the use of existing visualizations', 'Analyzing visualization ensembles'], additionalInformation: ['The survey emphasizes the need for visualization-tailored AI models due to the unique characteristics of visualization data.', 'Future research directions include improving reverse engineering techniques, developing AI models tailored to visualizations, and exploring big visualization data.'], methodology.dataCollection: A relation-search approach is applied, graph traversal over the citation and reference networks to collect publications from 10 research communities., methodology.dataAnalysis: An iterative categorization and labeling process is used to synthesize relevant work and develop a taxonomy organized around what, why, and how axes.",-1],[-8.3520975113,-0.632651031,"title: Towards Natural Language Interfaces for Data Visualization: A Survey, abstract: Utilizing Visualization-oriented Natural Language Interfaces (V-NLI) as a complementary input modality to direct manipulation for visual analytics can provide an engaging user experience. This article conducts a comprehensive review of existing V-NLIs, developing categorical dimensions based on a classic information visualization pipeline with the extension of a V-NLI layer. It highlights several promising directions for future work in the V-NLI community., authors: [{'name': 'Leixian Shen', 'affiliation': 'Tsinghua University, Beijing 100190, China'}, {'name': 'Enya Shen', 'affiliation': 'Tsinghua University, Beijing 100190, China'}, {'name': 'Yuyu Luo', 'affiliation': 'Tsinghua University, Beijing 100190, China'}, {'name': 'Xiaocong Yang', 'affiliation': 'Tsinghua University, Beijing 100190, China'}, {'name': 'Xuming Hu', 'affiliation': 'Tsinghua University, Beijing 100190, China'}, {'name': 'Xiongshuai Zhang', 'affiliation': 'Tsinghua University, Beijing 100190, China'}, {'name': 'Zhiwei Tai', 'affiliation': 'Tsinghua University, Beijing 100190, China'}, {'name': 'Jianmin Wang', 'affiliation': 'Tsinghua University, Beijing 100190, China'}], publicationVenue: IEEE Transactions on Visualization and Computer Graphics, publicationDate: June 2023, keywords: ['Data visualization', 'Natural language interfaces', 'Survey'], theoreticalFramework: The research is guided by the classic information visualization pipeline proposed by Card et al., extended with a V-NLI layer to develop categorical dimensions for classifying and reviewing V-NLI systems., mainPoints: ['V-NLIs enhance user experience by allowing natural language queries for data visualization.', 'A comprehensive review of existing V-NLIs is conducted, categorizing them based on a modified visualization pipeline.', 'Several promising directions for future work in the V-NLI community are identified.'], results: The survey presents a classification overview of existing works in V-NLI, identifying gaps in knowledge, methodology, interaction, presentation, and dataset aspects of the field., applications: ['Enhancing user engagement and experience in visual analytics.', 'Guiding future research in developing more robust and comprehensive V-NLI systems.'], additionalInformation: ['The survey highlights the need for incorporating advanced NLP models and domain knowledge in V-NLI systems.', 'Future research directions include improving system discoverability, leveraging user interaction history, and expanding the application of V-NLI in immersive analytics.', 'The study calls for the collection of large-scale datasets and the creation of new benchmarks to support more tasks, domains, and interactions in V-NLI research.'], methodology.dataCollection: An exhaustive review of relevant journals and conferences throughout the past twenty years (2000-2021), covering VIS, HCI, NLP, and DMM fields., methodology.dataAnalysis: Systematic analysis of collected papers to understand main research trends and categorize current work.",-1],[-8.0902938843,-0.4704812169,"title: TextTile: An Interactive Visualization Tool for Seamless Exploratory Analysis of Structured Data and Unstructured Text, abstract: We describe TextTile, a data visualization tool for investigation of datasets and questions that require seamless and flexible analysis of structured data and unstructured text. TextTile integrates operations that can be applied interchangeably to both structured and unstructured parts of the data to generate useful data summaries, organized in visual tiles in a grid layout for analysis and comparison. The system's effectiveness is validated through task analysis, use cases, and a user study., authors: [{'name': 'Cristian Felix', 'affiliation': 'New York University'}, {'name': 'Anshul Vikram Pandey', 'affiliation': 'New York University'}, {'name': 'Enrico Bertini', 'affiliation': 'New York University'}], publicationVenue: IEEE Transactions on Visualization and Computer Graphics, publicationDate: January 2017, keywords: ['Exploratory Text Analysis', 'Knowledge Discovery', 'Text Visualization'], theoreticalFramework: The work is grounded in the need for integrated analysis of structured and unstructured data, drawing from real-world data analysis problems identified through collaboration with domain experts., mainPoints: ['Introduction of TextTile, a tool designed for the integrated analysis of structured and unstructured data.', 'Identification of common tasks in data analysis that involve both structured data and unstructured text.', 'Development of a data visualization system that integrates data model organization, transformation operations, and graphical representations for analysis and comparison.', 'Validation of TextTile through use cases and a user study demonstrating its ease of learning and proficiency in carrying out nontrivial tasks.'], results: TextTile was validated to effectively support seamless analysis of structured and unstructured data, enabling users to easily learn and proficiently use the system for exploratory data analysis tasks., applications: ['Customer relationship analysis', 'Investigative journalism', 'Survey research', 'Analysis of online reviews and feedback'], additionalInformation: ['The system is based on a principled method integrating a data model, operations, and visualization for flexible data analysis.', 'Future work includes deploying TextTile in real-world settings, expanding NLP methods for text analysis, and exploring multi-attribute splitting for more complex analyses.', 'Key contributions include the identification of abstract tasks in data analysis involving text and structured data, and the development of an integrated set of operations for such tasks.'], methodology.dataCollection: Real-world data analysis problems gathered through interaction with domain experts across various fields., methodology.dataAnalysis: Implementation of a data processing pipeline in TextTile, consisting of filter, split, and summarize operations, applied to both structured and unstructured data.",2],[-7.9680953026,-0.4583095014,"title: TexTonic: Interactive visualization for exploration and discovery of very large text collections, abstract: TexTonic is a visual analytic system for interactive exploration of very large unstructured text collections. It visualizes hierarchical clusters of representative terms, snippets, and documents in a single, multi-scale spatial layout. Exploration is supported by interacting with the visualization and directly manipulating the terms in the visualization using semantic interactions. These semantic interactions steer the underlying analytic model by translating user interactions within the visualization to contextual updates to the supporting data model. The combination of semantic interactions and information visualization at multiple levels of the data hierarchy helps users manage information overload so that they can more effectively explore very large text collections., authors: [{'name': 'Celeste Lyn Paul', 'affiliation': 'US Department of Defense, Laurel, MD, USA'}, {'name': 'Jessica Chang', 'affiliation': 'US Department of Defense, Laurel, MD, USA'}, {'name': 'Alex Endert', 'affiliation': 'Georgia Institute of Technology, Atlanta, GA, USA'}, {'name': 'Nick Cramer', 'affiliation': 'Pacific Northwest National Laboratory, Richland, WA, USA'}, {'name': 'David Gillen', 'affiliation': 'Pacific Northwest National Laboratory, Richland, WA, USA'}, {'name': 'Shawn Hampton', 'affiliation': 'Pacific Northwest National Laboratory, Richland, WA, USA'}, {'name': 'Russ Burtner', 'affiliation': 'Pacific Northwest National Laboratory, Richland, WA, USA'}, {'name': 'Ralph Perko', 'affiliation': 'Pacific Northwest National Laboratory, Richland, WA, USA'}, {'name': 'Kristin A Cook', 'affiliation': 'Pacific Northwest National Laboratory, Richland, WA, USA'}], publicationVenue: Information Visualization, publicationDate: 2018, keywords: ['Text and document visualization', 'interactive visual analysis', 'geospatial visualization', 'adaptive user interfaces', 'user study'], theoreticalFramework: The research is grounded in the principles of visual analytics, emphasizing the importance of user interaction with visualized data to support sensemaking and analysis, particularly for large data sets that are difficult to understand using conventional methods., mainPoints: ['Introduction of TexTonic, a system designed for the exploration of large unstructured text collections through user-driven analytics.', 'Description of TexTonic\u2019s data processing and analytic pipeline, user interface, and interaction design principles.', \"Presentation of a user study conducted with experienced data analysts to evaluate the system's usability and effectiveness.\", 'Discussion on the implications of TexTonic for visual exploration and discovery tasks.'], results: The user study indicated that TexTonic was effective in supporting users to manage information overload and explore large text collections intuitively. Participants were able to learn and use the system quickly, finding it to be a powerful tool for discovery., applications: ['Supporting data analysts in exploring and discovering insights from very large text collections.', 'Facilitating the management of information overload by providing progressive visualization guided by user-driven analytics.'], additionalInformation: [\"The study highlighted the importance of semantic interactions in bridging the gap between users' mental models and the system's data model.\", 'Future work may explore the integration of different text analytics and the development of advanced search capabilities within TexTonic.'], methodology.dataCollection: Use of large text collections such as Wikipedia, containing over 4 million documents, to demonstrate TexTonic's capabilities., methodology.dataAnalysis: Application of text processing techniques like Rapid Automatic Keyword Extraction (RAKE), k-means clustering, and principal component analysis (PCA) for data model generation and visualization.",2],[-7.9168591499,0.055674538,"title: Interactive Text Mining Suite: Data Visualization for Literary Studies, abstract: This paper introduces the Interactive Text Mining Suite, a toolkit developed for digital humanists and corpus linguists to address challenges in applying text mining and visualization tools to literary studies. It emphasizes the integration of visual analytics and corpus linguistics methods to unveil hidden language patterns in literary texts, using both linguistically annotated data and natural language processing techniques., authors: [{'name': 'Olga Scrivner', 'affiliation': 'Indiana University Bloomington'}, {'name': 'Jefferson Davis', 'affiliation': 'Indiana University Bloomington'}], publicationVenue: Conference Paper, publicationDate: January 2017, keywords: ['Text Mining', 'Data Visualization', 'Literary Studies', 'Digital Humanities', 'Corpus Linguistics', 'Natural Language Processing'], theoreticalFramework: The paper is grounded in the transition from traditional close reading to distant reading approaches in literary studies, aligning digital humanities with corpus linguistics to explore large-scale digital collections through computational methods., mainPoints: ['Growing interest in visualization methods for literary text analysis.', 'Challenges in applying text mining and visualization tools to literary studies.', 'Introduction of the Interactive Text Mining Suite for digital humanists and corpus linguists.', \"Demonstration of the toolkit's ability to unveil hidden language patterns in literary texts.\", 'Integration of visual analytics and corpus linguistics methods.'], results: The toolkit enables the detection of stylistic differences and language patterns in literary texts, facilitating a synthesis of computational and humanistic modes of inquiry., applications: ['Enhancing literary studies by providing a user-friendly toolkit for text analysis and visualization.', 'Allowing digital humanists and corpus linguists to apply interactive control over documents for a more meaningful exploration of texts.'], additionalInformation: ['The need for a methodological shift from traditional close reading to distant reading approaches in literary studies.', 'Future development directions include enhancing the toolkit with additional features such as dynamic network graphs and stylometric analysis.'], methodology.dataCollection: Use of both linguistically annotated data and natural language processing techniques., methodology.dataAnalysis: Analysis of patterns of part-of-speech uses in Medieval Occitan manuscript Romance de Flamenca and its English translation through visual analysis at word, sentential, and document levels.",-1],[-8.1580610275,-0.2047036588,"title: The Language Interpretability Tool: Extensible, Interactive Visualizations and Analysis for NLP Models, abstract: The paper presents the Language Interpretability Tool (LIT), an open-source platform for visualization and understanding of NLP models. It integrates local explanations, aggregate analysis, and counterfactual generation into a streamlined, browser-based interface to enable rapid exploration and error analysis across a wide range of models., authors: [{'name': 'Ian Tenney', 'affiliation': 'Google Research'}, {'name': 'James Wexler', 'affiliation': 'Google Research'}, {'name': 'Jasmijn Bastings', 'affiliation': 'Google Research'}, {'name': 'Tolga Bolukbasi', 'affiliation': 'Google Research'}, {'name': 'Andy Coenen', 'affiliation': 'Google Research'}, {'name': 'Sebastian Gehrmann', 'affiliation': 'Google Research'}, {'name': 'Ellen Jiang', 'affiliation': 'Google Research'}, {'name': 'Mahima Pushkarna', 'affiliation': 'Google Research'}, {'name': 'Carey Radebaugh', 'affiliation': 'Google Research'}, {'name': 'Emily Reif', 'affiliation': 'Google Research'}, {'name': 'Ann Yuan', 'affiliation': 'Google Research'}], publicationVenue: arXiv, publicationDate: 12 Aug 2020, keywords: ['NLP models', 'Visualization', 'Model understanding', 'Interactive analysis', 'Counterfactual generation'], theoreticalFramework: The research is guided by the need for better understanding and interpretability of NLP models, focusing on model behavior analysis through visualization, counterfactual reasoning, and aggregate analysis., mainPoints: ['Introduction of the Language Interpretability Tool (LIT), a platform for NLP model visualization and analysis.', 'LIT supports a wide range of models and is highly extensible through a declarative, framework-agnostic API.', 'The tool enables users to explore model predictions, attention mechanisms, and the effects of input modifications.', \"Case studies demonstrate LIT's application in sentiment analysis, gender bias detection in coreference systems, and debugging text generation models.\"], results: The case studies illustrate how LIT can facilitate understanding of model behavior, identify biases, and debug errors through interactive exploration and analysis., applications: ['Rapid exploration and error analysis of NLP models.', 'Educational tool for understanding complex model behaviors.', 'Framework for research on model interpretability and bias detection.'], additionalInformation: ['LIT is open-source and under active development, with a focus on extensibility and support for a broad range of NLP tasks.', 'Future work includes adding new counterfactual generation plugins, metrics, and visualizations for various output types.', \"The tool's design principles emphasize flexibility, modularity, and ease of use, aiming to lower the barrier to sophisticated model analysis.\"], methodology.dataCollection: Use of existing datasets such as the Stanford Sentiment Treebank and Winogender for case studies., methodology.dataAnalysis: Interactive analysis through LIT's browser-based UI, including visualizations of embeddings, metrics, salience maps, and attention distributions.",2]]